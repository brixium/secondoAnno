Architettura dei calcolatori e sistemi operativi 
Martedì 17 settembre 2019

Prof. Donatella Sciuto (vice rettore) + Luca Stornaiuolo
RIceve su appuntamento
Prova in itinere ma funziona un po'diversamente
Prima parte del corso: architettura dei calcolatori
	Testo: David A. Patterson, John L.Hennessy; Struttura e progetto dei calcolatori edito Zanichelli; ->architettura dei calcolatori
	Testo 2ndo sem: dispense online su BeeP.  ->sistemi operativi e programmazione concorrente (Linux)
TDE disponibili su BeeP. 
Lezione misto tra slide e lavagna

Modalità d'esame: 2 prove separate anche agli appelli: 1 sull'architettura dei calcolatori, l'altra sui sistemi operativi.
Ogni prova assegna 16 punti, la si passa con almeno 7 punti, 18 su tutte e due.
È possibile sostenere le prove in appelli differenti.
Sconsigliato fare le prove insieme.
All'esame ti danno tutto quello che dovresti impararti a memoria, tipo Bolchini.

Partiamo col singolo processore
Programmazione multithread, non vedremo problemi di design: sicurezza, surriscaldamento, efficienza energetica.
Architettura del calcolatore è coordinamento di molti livelli di astrazione.

Linguaggio di alto livello > Instruction Set Architecture > codice binario
ISA è relativo ad una architettura di CPU. Ed è quella che divide il sw dall'hw.
Il SO nasconde le funzioni hardware al software fornendo interfacce.
Firmware è la più vicina all'hardware
Transistor > circuiti > porte logiche >|| microarchitettura > ISA (architettura) > Sistema runtime(VM, OS, FS) ||> programma/linguaggio.
SO gestisce: processi, memoria e File System.

Livelli di astrazione:
C > assembly (MIPS) > linguaggio macchina (MIPS) > descrizione architettura hw a blocchi > descrizione circuito logico (diagrammi schematici dei circuiti).

Temi:
1) ISA (cpaitolo 2 fino a 2.14 e appendice A escluse le parti in Java)
	-linguaggio assembly (MIPS)
	-tradurre da C in assembly
	-tradurre dall'assembly al codice macchina
2)componenti hw:
	-porte logiche
	-circuiti combinatori
	-elemeti di memoria
3)il processore
4)la gerarchia di memoria (cap.5 fino a 5.4)
5)il bus: introduzione

il capitolo 5.7 verrà trattato nella seconda parte del corso con i sistemi operativi.

Legge di Moore: ogni 2 anni / 18 mesi, ci sono 2X transistor. Oggi il trend si è rallentato un po'per problemi di architettura.

Principi fondamentali:
	il programma viene mandato in esecuzione, lo si manda in memoria e si invia la prima istruzione al processore
	dopodiché esecuzione sequenziale
Architettura di Von Neumann
	|-CPU con ALU, Registri+PC, controllo
	|-Memoria
	|-Interfaccia di I/0 <-->memoria di massa
	|-I/0 <--> tastiera/video
	^ bus di dati, indirizzi e controllo (protocollo).

Struttura del data path:
Programma in c: 
int a, b, c;
c = a + b;
^ 1 istruzione in c che diventano 4 istruzione assmbly:
	.carica a da memoria a registro
	.carica b da mem a reg
	.esegui somma dei 2 registri
	.spostamento dell'output ALU da registro a memoria.
in altre parole: Caricare c, a e b nei registri in memoria, poi si portano nei registri di ingresso dell'ALU e si portano ai bus di ingresso all'ALU.

Categorie di istruzioni:
	Registro-memoria
		-trasferimento dati tra registri CPU e la memoria centrale
		-l'unità di informazione trasferita è la parola (word)
	Registro-registro
		-utilizzano il contenuto dei registri per svolgere operazioni (tramite ALU) e memorizzano il risultato in un ciclo di data path.
		-ciclo di data path

Esecuzione delle istruzioni
	Ciclo Fetch-Decode-Execute
			1)prendi l'istruzione corrente dalla memoria e la metti nel registro istruzioni (IR)
			2)incrementa il PC in modo da contenere l'indirizzo dell'istruzione successiva
			3)determina il tipo dell'istruzione corrente (decodifica)
			4)se l'istruzione usa una parola in memoria, determina dove si trova
			5)carica la parola in un registro CPU se necessario
			6)Esegui l'istruzione
			7)torna al punto 1 e esegue l'istruzione successiva

L'istruzione è divisa in campi:
	campo codice operativo indica il tipo di operazione
	gli altri campi indicano gli indirizzi degli operandi oppure gli operandi stessi. Gli indirizzi possono riferirsi ad indirizzi di memoria o reg della CPU.
modalità di indirizzamento

Noi usiamo MIPS a 32 bit 
2 tipi di processori: 
	quelli che vogliono entrambi i dati su cui operare provenienti dalla memoria debbano essere caricati nei registri -> architetture LOAD STORE (quelle più moderne)

Il normale flusso di esecuzione di un programma può essere interrotto da un segnale di INTERRUPT per richiesta di intervento che un dispositivo I/O manda al processore.
Con esso i dispositivi di I/O possono segnalare cose al processore.

Un po'di storia: RISC e CISC
I primi computer avevano delle ISA semplici, via via rese sempre più complesse.
Negli anni '70 andavano molto i processori microprogrammati CISC, realizzati con l'idea di fornire istruzioni molto complesse che rispecchiassero i costrutti dei liguaggi ad alto livello. Microprogramma per realizzare istruzioni complesse. Falsa credenza che avessero delle implementazioni HW più efficienti.
Negli anni '80 c'è stato l'avvento dei RISC, di cui il MIPS fa parte. Istruzioni semplici, tempi di esecuzioni molto brevi.
Vantaggi del RISC: spazio risparmiato per implementazione istruzioni extra viene impiegato per memorie cache per velocizzare istruzioni; uniformità delle istruzioni per velocizzarne la decodifica; uniformità e prevedibilità dei tempi di esecuzione delle istruzioni permette di eseguire più operazioni in parallelo.
Intel creò un nucleo RISC ma aggiunge in hardware un assembler che traduce dall'assembly CISC all'allora nuovo RISC.

Noi utilizziamo il MIPS (R2000/R3000 RISC)
Usando l'interprete MARS o SPIM possiamo farlo.

Registro da 32 bit, possiamo indirizzare fino a 2^32 B di memoria (4GB).
La memoria è indirizzabile a byte con parole da 4 byte.
Gli ultimi 2 bit alla fine della parola servono a poco.

Bus dati
Bus indirizzi
Bus di controllo

Esempio: operazione di lettura dalla memoria
	il bus indirizzi viene riempito con l'indirizzo della parola desiderata e inviato alla memoria
	quando la memoria ha finito di leggere la parola richiesta, il dato viene trasferito al bus dati e la CPU può prelevarlo
	nella struttura a bus singolo tutte le unità del calcolatore sono connesse al bus.

Ripasso numeri binari


CAPITOLO 2

Introduzione Assembler

Per il C la compilazione avviene in 3 fasi: compilazione (che crea file oggetto .obj), linking (con anche programmi di libreria), caricamento ed esecuzione.
Il linguaggio assembler è più primitivo: no controllo di flusso, solo GOTO. Linguaggio molto restrittivo (es. istruzioni aritmetiche hanno numero piccolo e fisso di operandi). Due processori con lo stesso linguaggio macchina hanno la stessa architettura anche con implementazioni hw diverse.
Incrementare il Program Counter lo fa avanzare di 4 (essendo a 32 bit).
I primi 6 bit indicano l'operazione da eseguire. I primi 6 bit a 0 indicano un'operazione aritmetica, descritta dagli ultimi 6 bit.
Utilizzando un traduttore inverso o disassemblatore posso tradurre dal linguaggio macchina in assembly.
I comandi con dei punti danno delle direttive all'assembler: 
	.text e .data indicano che le linee successive contengono istruzioni o dati
	.align n: indica l'allinamento su 2^n
	.global main: l'etichetta main è globale, ossia visibile dal codice in altri file
	.asciiz: area di memoria che memorizza una stringa terminata da 0
sw è store word
sd è store double
lw è load word
mul moltiplicazione
ble branch less or equal (salta se minore o uguale (sottointeso a 0))

Categoria di istruzioni:
	aritmetico logiche
	trasferimento memoria
	di controllo (flusso exec)
Esse hanno una codifica, un formato (nel MIPS ce ne sono 3, ciascuna per ciascuna categoria).
Le istruzioni del MIPS hanno solo 2 operandi e 1 risultato.
Sia operandi che risultato devono essere contenuti nel registro.
Non confondere variabili e registri. Variabili infinite, 32 registri codificati in bit, da 0 a 31. Sono numerati col $ davanti ($0, $1, ..., $31). Alcuni hanno dei nomi simbolici. $0 ha dentro 0, $1 è riservato (chiamato anche $at). I valori di ritorno sono salvati in $2 e $3, poi c'è il resto.


Mercoledì 18 settembre 2019

26enne Luca Stornaiuolo luca.stornaiuolo@polimi.it
Iscritto nel 2012, laurea triennale nel 2015. Si è iscritto ad una laurea magistrale ed era spaventato dall'ostacolo dell'inglese. Nel 2016 entra nel NECST (laboratorio basato sull'hardware). Hackaton. may 2017 NGC @San Francisco. 
Forze oscure: prof.Santambrogio, collaborazione IBM<->Polimi a Cambridge, Massachussets. Laurea magistrale a ottobre 2017.
Da nov.2017 dottorato: dura 3 anni e fai ricerca sull'ing.informatica.

Assembler MIPS
Libro di testo: Patterson Hennessy capitolo 2, usiamo MARS
In MIPS ci sono operandi e registri.
variabili =/= registri
I 3 tipi di istruzioni MIPS:
	(R)egister: operazioni aritmetico-logiche. Diverse istruzioni.
		istruzione destinazione, src1, src2
		add: serve per sommare il contenuto di due registri
			es: add rd, rs, rt //andrà a sommare rs e rt e metterà il risultato in rd.
		sub: sottrae
	(I)mmediate

	(J)ump

Esempio R: a = (b+c) - (d-f) + g.
$s1 è b, $s2 è c

trasferimenti con la memoria: istruzioni lw e sw

Load Word (LW)
lw carica il contenuto dalla memoria
es. lw $s1, 48($s2)
                ^base register che contiene il valore del base address
			 ^offset
		^dove va a salvare

SW è analogo a lw ma è store
es. sw $s1, 96($s2)
				^a questa locazione + offset viene assegnato il valore dentro s1

li e la, load immediate e load address
li $v0, 4 (carica la costante 4 in v0)
la $a0, num1 (carica l'indirizzo num1 in a0)

Differenza tra la e lw

Big endian e little endian. MIPS è in grado di operare con entrambi i metodi
Big endian è avere i byte enumerati da sinistra a destra, little endian è da destra a sinistra.

varianti dell'addizione: addi(immediata), addu (senza segno) e addiu (immediata e senza segno).

Esistono registri referenziabili e non referenziabili 
Moltiplicazione: mult rs rt, senza segno: multu rs rt
il registro del risultato della moltiplicazione è implicito. È messo in due registri speciali: hi e lo.
Il risultato della moltiplicazione si preleva dal registro hi e da lo tramite due operazioni: mfhi e mflo

Divisione: div e divu. Simile a prima

Istruzioni logiche
	and			and rd, rs1, rs2
	or			or rd, rs1, rs2
	nor			nor rd, rs1, rs2
	lshift		sll rd, rs, #bit
	rshift		srl rd, rs, #bit
esistono anche andi e ori ovvero and/or bit a bit tra un operando e una costante

Se devo fare una moltiplicazione per un multiplo di due uso lo shift a sinistra in un solo ciclo di clock anziché 4 o 6.
I bit inseriti durante lo shift sono settati a 0.

Array
L'indirizzo dell'iesimo elemento di un array si troverà nell'elemento br + (4*i) //4 sono il numero di byte in una word

(J)ump: istruzioni di salto.
Normalmente l'esecuzione è sequenziale.
Il Program Counter (PC) indica dove si trova la prossima istruzione da eseguire, quindi normalmente PC=PC+4.

Si può modificare il flusso di istruzioni con:
	-salto condizionato (branch) -> al verificarsi di una condizione viene eseguito. 
		Se la reg1==reg2: beq reg1, reg2, ind_salto
	-salto incondizionato (jump) -> viene sempre eseguito
		jump: j addr
		jump and link: jal
		jump register: jr reg

Etichette (labels)
vengono usate per essere ritrovate facilmente, l'assembler le sostitiusce in fase di compilazione

Esempio:
	if(i==j)
		f=g+h;
	else
		f=g-h;
	
	tradotto in assembly.

		bne	$s3, $s4, Else #Else è un'etichetta, non è realmente scritta in memoria
		add	$s0, $s1, $s2
		j	End_if
Else:	sub	$s0, $s1, $s2
End_if:	...

istruzione slt e sltu

Altro esempio:
if(i<j) ...


Vai con la seconda slide PDF
Formato istruzioni di tipo R: istruzioni aritmetico-logiche tra registri
op (opcode): tipo di istruzione,	6 bit (per le R sono tutti a 0)
rs: reg contenente il primo operando sorgente, 5b
rt: " " " secondo op. sorgente, 5b
rd: " " il risultato (destinazione),5b
shamt: shift amount, 5b
funct: variante dell'operazione, 6b (somma, sottrazione, ...)

Istruzioni di tipo I (lw, sw, addi, slti)
op 6 bit
rs 5b = reg base
rt 5b = reg dest.
indirizzo: 16 bit = spiazzamento, offset

istruzioni di salto condizionato (tipo i)

Giovedì 19 settembre 2019 (Stornaiuolo)
Continiuamo le slide di ieri.
Formato istruzioni di tipo J.

Per saltare ad indirizzi > 2^28 c'è un comando apposta
pseudoistruzione la (load address)
Le operazioni aritmetico-logiche si trovano nei registri
Registri sono vicini al processore, la memoria invece è distante e occorre che venga chiamata.


Terza slide

Passare da C (alto livello) ad Assembly (basso livello)

4 fasi per tradurre:
- analisi sintattica e trattamento errori (statico)
- generazione del codice macchina in forma simbolica
- ottimizzazione del codice macchina (facoltativo)
- assemblaggio (traduzione in codifica numerica) e linking 

Occhio alle pseudoistruzioni: istruzioni più astratte e intuitive ma devono essere tradotte per l'ISA, non sempre automatico.

Chiamate di sistema: syscall
	mettere il codice di chiamata nel reg $v0, argomenti da $a0 ad $a3
	chiamare la syscall
3 segmenti essenziali del processo:
	codice
	dati
	pila (stack (dall'alto al basso) e heap (dal basso verso l'alto))
Dichiarare i segmenti tipici
.global main = entry point
.data, .text

Esempio:
codice C: 	int a, b, c;
			a=b+c;
Assembly + mappatura:
	a: .word # la sua memoria sarà per le word 100, 101, 102, 103
	#.word è una macro
	lw $t0, 104($0) 

Array:
A: .space 80 # occupa 80 byte
In assembler per salvare le variabili ti devi salvare dello spazion in memoria
Variabile globale ha spazio statico ed è scritta in maiuscolo per convenzione, sono allocate in MIPS a partire dall'indirizzo 0x1000000
macro silde 28
Ci sono tutti i tipi, array, puntatori, struct.
Dichiarazione di funzione
Consideriamo fino a 4 parametri perché poi bisogna inventarsi dei trucchi
Il valore in uscita va restituito in v0
area di attivazione della funzione
I sottoprogrammi
-> creato record di attivaione sullo stack quando viene chiamato, deallocato alla sua fine
jump and link
side effect da gestire utilizzando la pila per salvare le informazioni
Problema: i registri sono condivisi sia dalla funzione chiamante che dalla chiamata (sovrascrittura). Per evitarlo, usare pila.
la pila serve per creare spazio per variabili locali della funzione
lo stack è una pila LIFO (last in, first out), indirizzata dai più grandi ai più piccoli.
Operazioni più utilizzate sono la push e la pop. Necessario avere puntatore in cima allo stack
Studiare la slide 47 della slide "gestione dello stack MIPS"
Implementazione della push e pop in assembly
PUSH: puntatore che punta alla cella successiva vuota, quindi per AUMENTARE la pila bisogna TOGLIERE indirizzi dallo stack pointer.
alla fine deallocare spazio nello stack (es. addi $sp, $sp, 24) =>aumentare lo stack pointer per deallocare dalla pila
Stack frame: area di attivazione.
Frame pointer è il punto di inizio della funzione. È un modo per deallocare in un colpo solo tutto quello che era usato dalla funzione.

Prologo del chiamante: salvo quello che mi serve.
Prologo del chiamato: salvo le mie info
Epilogo del chiamato: dealloco
Epilogo del chiamamnte: pulisco

Il chaiamnte si occupa di salvarsi dei registri temporanei, gli argomenti inviati alla funzione, i registri v0 e v1 (tutto ciò solo se necessario).
il chiamato salva i registri s0-s7 che sono quelli permanenti, per poi fare le operazioni che vuole; infine le rimette a posto una volta terminata l'esecuzione.
Quando la funzione chiamante non deve salvare nulla?
	Se al chiamante nessuno dei valori che normalmente si salva servono più, non li salva.
Quando la funzione chiamata non deve salvare nulla?
	Se il chiamato non deve sporcare i registri s0-s7
Ordine di salvataggio dei registri sullo stack (area di attivazione, slide 64)
precisazioni sul FP frame pointer
Procedura foglia è quella che non chiama nessun altro
Traduzione del fattoriale da C in assembly
Le funzioni non foglia si salvano sullo stack il ra return address


Martedì 24 settembre 2019
Esercizio di traduzione da C in assembler
Programma C che trova valore max in un array di valori

Trasformare la load address
la $t0, VETT
in una load word
lw, reg_dest, spiazzamento(reg_base)
lui

lui $t0, %hi(VETT) #la parte maggiore di vett (i primi 16 bit su 32 più significativi) è caricata (carico i 16 bit + significativi)
ori $t0, %lo(VETT) #faccio la or immediata tra $t0 e la parte bassa di VETT (che è a tutti 0), per rimette insieme i due pezzi
#in spiccioli, la istr. "la" si divide in lui e ori
altra traduzione di pseudoistruzione se ho spazio per 16 bit con istruzioni da 32
lw $t0, VETT
#spiazzamento, global pointer
lw $t0, %gp_al(VETT)($gp)

Adesso le funzioni: vedi ese3.asm


Mercoledì 25 settembre 2019

Assemblatore e linker
Traduzione programma da C a eseguibile:
1)Programma C
2)Programma assembler
3)Traduzione pseudoistruzioni in assembler
4)Traduzione riga per riga delle istruzioni in codifica binaria inserendo nella tabella dei simboli "etichette" di cui è necessario ricavare un indirizzo quando definite all'interno di un modulo
5) File oggetto: modulo in linguaggio macchina + funzioni libreria
6) Eseguibile: programma in linguaggio macchina -> memoria
Tabella dei simboli (utilizzata per i moduli).
Dove vengono salvati in memoria i moduli? Quando assemblo non lo so
Si assume che i moduli partano dall'indirizzo 0 della memoria
Il file oggetto è composto da:
	header(con dimensione in byte del file e la posizione dei vari segmenti)
	codice tradotto
	parte DATI statici
	informazioni di rilocazione (identificano istruzioni e dati che dipendono da indirizzi _assoluti_ durante l'esecuzione)
	informazioni per debug

La parte cruciale è inserire indirizzi alle etichette.
Può essere che una etichetta venga usata prima di essere definita.
Per cui il compilatore legge il file alla ricerca di etichette e le inserisce nella tabella dei simboli.

_Tabella dei simboli_ contiene:
	etichette associate alle direttive dell'assembly (.eqv) <symbol, value>
	ettichette che definiscono variabili nel segmento dati <symbol, relative address>
	e. che definiscono istruzioni di salto <symbol, address>
Indirizzi rilocabili perché calcolati rispetto al segmento di partenza (testo, dato)

_Tabella di rilocazione del modulo_
Contiene le informazioni sulle istruzioni tradotte in modo incompleto, c'est a dire le informazioni in cui il riferimento simbolico è una variabile del segmento dati, quindi convenzionalmente, l'assemblatore traduce le variabili scalari con 0($gp) (global pointer, che punta ad un'area del segmento dati).
Per i vettori la traduzione avviene tramite l'utilizzo della load address + or immediate (lui+ori), con immediati convenzionali a 0.
Le istruzioni di salto di tipo J, il simbolo è posto a 0 per convenzione.
La tabella è formata da entry di questo formato:
<indirizzo dell'istruzione, codice operativo della funzione, simbolo non risolto>

Esempio: sorgente procedura B:

.text
B:	bne $a0, $0, E
	sw $a0, Y
E:	la $t0, W

.data
Y:	.word 0

i riferimenti a W e Y sono nella tabella simboli
(VS_REL -IADDR_REL +4)/4 = istruzione di salto
Ho capito poco di questo esempio
La tabella di rilocazione contiene le informazioni con riferimenti al segmento dati e istruzioni con riferimenti assoluti
Questa breve parte è sull'appendice A del libro, caricata su beep
Linker: si occupa di mettere insieme i moduli, gestendo la memoria. Alla fine produce un file eseguibile con la memoria dei moduli ordinata. Assume quindi che il primo sta all'indirizzo 0, e poi gli altri a seguire in maniera sequenziale per codice e dati. A questo punto corregge le tabelle e traduce indirizzi.

Memoria virtuale
Se il programma è piccolo viene caricato tutto, se è grande viene caricato a pezzi.
Creo un modulo di memoria come riferimento per tutti.
Organizzazione della memoria:
	la prima parte è riservata dal SO
	quella dove sarà caricato il codice 0x0040 0000
	segmento dati statici: 0x1000 0000
	segmento dati (memoria RAM malloc)
	segmento stack. indirizzo max utilizzabile è 0x7FFF F(<-forse questa è una E)FFC
	$sp è un indirizzo preciso per prelevare dati statici

Il segmento dati statici non è rappresentabile su 16 bit.
Come faccio a rappresentare l'indirizzo 1001 0020?
Lo faccio a pezzi: il primo lo carico con la lui (load upper immediate) (0x1001) e il secondo con la lw $1 0x0020($s0)
ora per caricare in s1 il contenuto della cella al nostro indirizzo basta sommare i due pezzi con la ori
Rilocazione del modulo (solo per indirizzi relativi)

La memoria virtuale è quello che potenzialmente posso indirizzare (come memoria) per il programma

1) determinare la posizione in memoria dei moduli a partire dall'indirizzo 0 e poi in maniera sequenziale
2) creazione della tabella dei simboli globale costituita dall'unione delle tabelle di simboli di tutti i moduli che devono essere collegati, modificari (rilocati) in base all'indirizzo del modulo a cui appartengono
	Segmento dati =/= 
3) Correzione dei riferimenti nei moduli (*)
	ISTR
	IADDR
	VS: valore di S nella tabella globale
	GP: global pointer

Regole:
ISTR è in formato J(ump): inserise VS/4 nell'istr
	 è un salto in formato I: (VS-(IADDR+4))/4
	 è aritmetico/logica in formato I: inserire i 16 bit meno significativi di VS (VS_Low)
	 è di tipo load o store: inserisco VS - GP
	 è di tipo lui: inserisco i 16 bit più significativi di VS (VS_High)

Tabella di rilocazione dei moduli
Indirizzo	Istruzione
-File/modulo A
40 0000		lw $a0, 0($gp)	*
40 0004		beq $a0, $0, 0	*
40 0008		jal 0			*
-File/modulo B
40 000C		bne $a0, $0, 1
40 0010		sw $a0, 0($gp)	*
40 0014		lui $t0, 0		*
40 0018		ori $t0, $t0, 0	*
-Dati
A X 1000 0000	128
- W 1000 0004	0x12345678
B Y 1000 0008	0

Il professor Santambrogio ci parla delle iniziative al Campus Leonardo per gli studenti, complementari alla parte di studio

a questo punto ho il file eseguibile, salvato sul disco fisso, viene portato nella memoria centrale, presi gli argomenti di ingresso al main, registri inizializzati, caricati lo stack pointer e viene inserito nel PC l'indirizzo della prima istruzione da eseguire 
Caricamento dei parametri a0-a3
Cosa succede alle funzioni di libreria? Una volta il linker agganciava anche quelle all'eseguibile, adesso non più.
Le librerie vengono caricate dinamicamente quando il programma è in esecuzione (DLL: dynamic link library) e viene poi agganciata al programma

in questa lezioni ci ho capito molto poco

Giovedì 26 settembre 2019 (esercitazione col ragazzo)
Ricorsione, Assemblatore (e linker) varie (frame pointer, maschere bianrie, ...)

Ricorsione: MIPS con variabili intere a 32bit, fp (frame pointer = punta all'inizio dell'area memoria funzione. Di solito non viene usato se non in casi speciali) non in uso, variabili allocate nei registri, se possibile; si salvano solo i registri necessari

Svolgere i seguenti 4 punti:
vai a vedere 20190926/ese1.c e ese1.asm

esercizio nuovo, supponiamo di avere tanti moduli che devono essere assemblati in dei file oggetto. Problema sorge quando ci sono dei riferimenti esterni.

Esercizio assemblatore

All'esame sicuramente traduzione da C a assembly e poi un esercizio strano tipo
-utilizza mappe di bit/byte per recuperare il numero in memoria, se è a 0, ...
-questo che ci propone lui

Ci sono due moduli con delle cross-references e compilare le 3 tabelle tenendo contro dei due moduli
breve ripasso dei numeri decimali / esadecimali / binari


Martedì 1 ottobre 2019

Architettura del processore

Progettare il processore MIPS. Servono gli oggetti base elettronici, principalmente transistor che immaginiamo binari ma in realtà ci sono due livelli di tensione, basso (0 V) e alto (1.8 V). Noi utilizzeremo dei circuiti elementari, non scendiamo ai transistor.
Noi utilizzeremo dei circuiti elementari, non scendiamo ai transistor.
Due grandi classi di circuiti elementari:
	- combinatori: il circuito produce un'uscita nello stesso istante dell'ingresso (semplici) ma non hanno memoria (l'uscita è in funzione dell'ingresso).
	- sequenziali: l'uscita al tempo t è funzione degli ingressi al tempo t ma anche dello stato, la storia degli eventi passati

cenno di porte logiche.
Specifica delle funzionalità->rete logica
Algebra di commutazione è il punto di partenza. È parte dell'algebra booleana e utilizza solo 0 e 1.
Variabili logiche possono assumere solo valore 0 oppure 1. x=0 se x=/=1 e viceversa.
Operatori:
	negazione: NOT f(x)=0 => x=1; f(x)=1 => x=0.
	somma logica: OR f(x,y)=0 => x=y=0 else f(x,y)=1
	prodotto logico: AND f(x,y)=1 => x=y=1 else f(x,y)=0
(sono raccolte nelle tabelle di verità)

Proprietà fondamentali dell'algebra di commutazione
____________________________________________________________________
				|	AND(*)			|	OR(+)						|
----------------|-------------------|-------------------------------|
identità		|	1*x=x			| 0+x=x							|
elemento nullo	|	0x=0			| 1ORx=x						|
idempotenza		|	X*X=X			| XORX=X						|
inverso			|	X AND (!X)=0	| XOR(!X)=1						| (! è il negato)
assorbimento	| X AND (X+Y)=X		| X+X*Y=X						| (serve per semplificare)
pr.commutativa	| XY = YX			| XORY = YORX					|
pr.associativa	| (XY)Z = X(YZ)		| (X+Y)+Z = X+(Y+Z)				|
pr.distributiva	| X(Y+Z)=XY+XZ		| X+YZ=(X+Y)(X+Z)				|
teo.di De Morgan| !(X*Y)=!X+!Y		| !(X+Y)=!X*!Y					|
teo del consenso| XY+!XZ+YZ=XY+!XZ	| (X+Y)(!X+Z)(Y+Z)=(X+Y)(!X+Z)	|
--------------------------------------------------------------------|

Prova a semplificare questa funzione applicando questi teoremi
f = A+!AB+!ABC =(mia soluzione)= A(1+0B+0BC) = A sbagliata
SOLUZIONE CORRETTA: applicando la proprietà distributiva + identità = A+!AB(1+C) = per propr. elemento nullo = A+!AB1 = applico propr.distributiva = (A+!A) (A+B) = 1*(A+B) = A OR B

Specifica della funzionalità può essere fornita come:
	tabella delle verità
	funzione logica
	rete logica 
Esempio:
Per esprimere 3 uscite devo dare 3 eq.logiche. Come faccio a scrivere la funzione logica da una descrizione a parole
Supponiamo che l'uscita D assume valore 1 sse almeno uno dei 3 ingressi ha valore 1, l'uscita F assume 1 sse tutti e 3 gli ingressi hanno valore 1 e l'uscita E assume valore 1 sse esattamente 2 ingressi hanno valore 1.
Risposta:
L'uscita D si esprime con: A OR B OR C = D
L'uscita F diventa: A AND B AND C = F
L'uscita E è un po'più complessa. A*B=1, C deve essere 0 (1/3 caso)
_tabella_
A B C | E D F
0 0 0 |	0 0 0
0 0 1 |	0 1 0
0 1 0 |	0 1 0
0 1 1 |	1 1 0
1 0 0 |	0 1 0
1 0 1 |	1 1 0
1 1 0 |	1 1 0
1 1 1 |	0 1 1
---------
Quindi E = !ABC+A!BC+AB!C

Disegni delle porte logiche:
NOT è un triangolo con 1 ingresso che ha un pallino (base) ed 1 uscita (punta). (spesso si usa solo il pallino senza triangolo)
OR è una punta di freccia: le entrate nella parte concava, l'uscita nella freccia
AND è un semicerchio con gli ingressi nel piatto e 1 uscita

Esempio A+B+C. Sono eseguite prima A+B e poi il risultato + C se ho un operatore binario, se è ternario uso una porta a 3 ingressi. Ci ci mette più tempo sono i segnali A e B che devono attraversare due porte, mentre C una sola
Esempio A*B*C che diventa (A*B)*C.
Esempio dell'uscita E=!ABC+A!BC+AB!C di prima. Cammino + lungo è quello di A che si fa 1 not, 2 and e 2 or

NAND (NOT AND) e NOR (NOT OR) sono operatori funzionalmente completi
Con il NAND posso realizzare il NOT, l'AND e l'OR
___NAND____
X Y | !(XY)
----|------
0 0 |	1
0 1 |	1
1 0 |	1
1 1 |	0

___NOR_____
X Y | !(X+Y)
----|-------
0 0 |	1
0 1 |	0
1 0 |	0
1 1 |	0

Come si fa un NOT usando un NAND? Così: !(XX) = !X+!X = !X
AND si fa mettendo NOT dopo il NAND. Così: !!(XY) = XY
OR con NAND: X+Y = !(!X !Y)
Altri operatori sono lo XOR (OR esclusivo) e XNOR
XOR si disegna come una doppia punta di freccia.
__XOR____
X Y | XOR
0 0 |	0
0 1 |	1
1 0 |	1
1 1 |	0

___XNOR___
X Y | XNOR
0 0 |	1
0 1 |	0
1 0 |	0
1 1 |	1

Scrivere la XOR con solo NOT, AND e OR
f = (x*!y) || (!x*y)
Scrivere la XNOR con solo NOT, AND e OR
f = !(X*Y) || (X*Y)

Per costruire la notazione dal disegno si va da sinistra a destra e si compone
Specifica a parole
	\->Tabella delle verità
		\->Funzione logica

Esercizio:
X Y Z | f
------|---
0 0 0 | 0
0 0 1 | 0
0 1 0 | 0
0 1 1 | 0
1 0 0 | 1
1 0 1 | 0
1 1 0 | 1
1 1 1 | 1
Prendo i 3 termini che la funzione mette a 0 e uso la prima forma canonica sottostante.
1 0 0 lo esprimo come X*!Y*!Z
1 1 0 si esprime come X*Y*!Z
1 1 1 lo scrivo come X*Y*Z
Infine faccio la somma logica di questi tre termini
f = (X*!Y*!Z)+(X*Y*!Z)+(X*Y*Z)
^^questa formula si può semplificare di molto usando le reogle qui sotto.
Adesso risolvo con la seconda forma canonica:
X|Y|Z & X|Y|!Z & X|!Y|Z & X|!Y|!Z & !X|Y|!Z
^^anche qui può essere semplificato
f = X(Y+!Z) <-funzione semplificata

Esistono 2 forme standard per semplificare le funzioni logiche
1ma forma canonica: 
	Ogni funzione f può essere specificata mediante la somma logica (OR) di tutti e soli i termini prodotto (AND) delle variabili di ingresso corrispondenti al valore 1 assunto dalla funzione
	Termine prodotto (MINTERMINE): prodotto logico (AND) di tutte le variaibli in ingresso della funzione prese in forma naturale se sono = 1, e in forma negata se sono = 0 nella configurazione di ingresso
2nda forma canonica (è duale della prima):
	f può essere espressa come il prodotto logico (AND) dei termini somma (OR) delle variabili in ingresso corrispondenti agli zeri della funzione e il termine somma, che viene chiamato anche MAXTERMINE, è la somma logica delle variabili in ingresso in forma naturale se hanno valore 0 e in forma complementata se hanno valore 1

Domani vediamo i componenti combinatori


Mercoledì 2 ottobre 2019
Sintesi combinatoria
Data una specifica, possiamo usare una tabella delle verità (solo quando ci sono pochi ingressi) oppure con la equazione logica.
Dalla tabella delle verità si può ricavare l'equazione con la prima e la seconda forma canonica. Prima è somma di prodotti e la seconda è un prodotto di somme. Questa rappresentazione non è ottima perché non ha il numero minimo di variabili.
Esemio di ieri: f = x(!y)(!z)+xy(!z)+xyz
					1  0  0  ,1 1 0, 111
È semplificabile utilizzando la proprietà sitributiva -> f=x(!y!z+y!z+yz).
Applico di nuovo la stessa pr. -> f=x(!z(!y+y)+yz) ->(mi avvalgo del fatto che !y+y=1 e 1*j=j) f=x(!z+yz)
A questo punto applico la proprietà dell'assobimento al contrario: !z=!z+y*!z
f=x(!z+y!z+yz) =x(!z+y(!z+z))=x(!z+y)

Blocchi combinatori (slide "Il livello logico digitale" disponibile online)
I tipici blocchi funzionali combinatori sono:
	1)multiplexer (MUX): ogni ingresso è numerato, c'è un ingresso di selezione che decide l'uscita. A forma di trapezio.
		Esempio MUX: 1 ingresso di selezione, 2 input, 1 output. L'ingresso di seleziona determina l'output. Tabella verità:
I1 |I2 |SEL|OUT
---------------
0	0	0	0
0	1	0	0
1	0	0	1
1	1	0	1
0	0	1	0
0	1	1	1
1	0	1	0
1	1	1	1
		In questo caso la formula logica è: C=!SA+SB. Dove C è l'uscita, S è la selezione, A è il primo ingresso e B il secondo ingr.
		Esempio se il MUXer ha più di 2 ingressi (4 in questo caso), dovraà avere più ingressi di selezione (in questo caso 2 (2^2))
		Se voglio un muxer a 2 ingressi dati da k bit devo mettere in cascata più muxer semplici da 2 ingressi che hanno tutti la medesima selezione in input.
		
	2)demultiplexer (DEMUX): meno ingressi, più uscite e controllo. Il controllo decide dove inviare l'uscita
	tabella verità
	I S1 S2 01 02 03 04
	D 0  0  D  0  0  0
	D 0  1  0  D  0  0
	D 1  0  0  0  D  0
	D 1  1  0  0  0  D

	3)Decodificatore (DECoder)
		non fa passare un dato ma determina l'uscita a seconda degli ingressi (inngressi < uscite)
		tab verità:
		i1|i2|u0|u1|u2|u3|
		0 |0 |1 |0 |0 |0
		0 |1 |0 |1 |0 |0
		1 |0 |0 |0 |1 |0
		1 |1 |0 |0 |0 |1
		con le porte logiche si fa mettendo degli and in cascata con alcuni not davanti. Tanti and quante uscite
	4)Comparatore o confrontatore:
	Ha due gruppi di ingressi A e B da n>=1 bit ciascuno e 3 uscite: a<b, a>b e a=b. Sulle slide esempio di confrontatore di numeri a 2 bit. Se i numeri in ingresso da A e da B hanno 2 bit, due ingressi per ciascun gruppo, le uscite sono sempre 3.

	5)Shifter combinatorio: (sempre di 1 posizione)
		1)scorrimento verso sinistra (moltiplicazione *2: aggiungere uno zero da destra)
		2)scorrimento verso destra   (divisione *2: aggiungere uno zero da sinistra)
		S/!D indica in che direzione shiftare (0=verso destra, 1=verso sinistra)
				Lshift		Rshift
		Out(n)	I(n-1)		New bit(0)
		Out(i)	I(i-1)		I(i+1)
		Out(0)	new bit(0)	I(1)
	Componenti aritmetici (somma e sottrazione)
	6)Sommatore o addizionatore: half adder (semisommatore) e full adder 
		Half adder ha due ingressi e due uscite. In ingresso i due numeri e in uscita la somma (XOR) e il riporto (carry)
		\-> è come fare la somma in colonna. Sum = A(XOR)B, carry= A&B
		Full adder: ha 3 ingressi (2 numeri e carry) e 2 uscite: sum e carry
		\-> sum=A(XOR)B^carry (^ è xor), il carry out sarà: ABCarryin+AB!carryin+A!Bcarryin+!ABcarryin che semplificato diventa A(B+carryin)+Bcarryin
		Per un semplice sommatore a k bit bisogna fare un half adder all'inzio e poi full adder fino alla fine. Problema delle prestazioni: il cammino più lungo è quello del carry che fa aspettare tutti i full carry. Nella realtà i calcolatori hanno un circuito che predica il carry. Questo sistema si chiama "carry look ahead".
		Moltiplicatore Dadda è figlio del prof.Dadda del PoliMi
		Noi vediamo il sommatore come una scatola chiusa.

		Sottrattore. Analogamente al sommatore ci sono: semi-sottrattore e sottrattore intero
Problemino: in ingresso due numeri interi naturali positivi a k bit e un ingresso di controllo. in uscita un numero intero binario naturale Z da k bit. Su Z deve presentarsi la somma A+B se C=0, la differenza A-B se C=1. In hardware questa cosa si fa in modo diverso dal software, che controlla prima l'ingresso di controllo. Si fa prima sia la somma e la sottrazione e poi se vede cosa mandare in output, attravero un multiplexer che riceve in ingresso somma e sottrazione e in controllo C. L'uscita sarà Z. È lo stesso modo in cui ragiona l'unità aritmetico-logica del processore (ALU) che sanno fare somma in C2, AND, OR, NOT e comparatore.
Esempio ALU a 2 bit e 2 bit di controllo con multiplexer.
Nell'appendice B troviamo:
	Numeri reali espressi in IEEE754
	Il segnale di zero
	L'indispensabile _Overflow Detection_

Esercizi su parte combinatoria e sequenziale.
1) overflow. Progettare circuito combinatorio che segnali overflow di una somma di numeri in complemento a due. Qui ci viene in mente la Bolchini: overflow non si verifica se gli operandi hanno segno discorde. Se gli operandi hanno segno uguale ma il risultato ha segno opposto, si è verificato overflow.
Tabella verità. s1: bit + significativo 1mo operando, s2: bit + significativo 2ndo operando, sr: bit + sign. risultato
s1|s2|sr|OvF
0 |0 |0 |0
0  0  1 |1
0  1  0 |0
0  1  1 |0
1  0  0 |0
1  0  1 |0
1  1  0 |1
1  1  1 |0

Scrivere la prima forma canonica di ciò. OvF=(!s1*!s2*sr) + (s1*s2*!sr)
Disegnare il circuito
2)Rete combinatoria con 3 ingressi (A, B, C) e 2 uscite (C1 e C0)
Le due uscite devono rappresentare in binario naturale (intero) il conteggio del numero di uni presenti sugli ingressi ABC
tabella verità:
 |A|B|C|C1|C0
0|0|0|0|0 |0
1|0|0|1|0 |1
2|0|1|0|0 |1
3|0|1|1|1 |0
4|1|0|0|0 |1
5|1|0|1|1 |0
6|1|1|0|1 |0
7|1|1|1|1 |1
1ma forma canonica:  C0 = (!A!BC)+(!AB!C)+(A!B!C)+(ABC); C1= !ABC+A!BC+AB!C+ABC
2nda forma canonica (vado a vedere gli zeri della funzione, normali se =0, negati e =1):
C0 = (A+B+C)*(A+!B+!C)*(!A+B+!C)*(!A+!B+C)
C1 = (A+B+C)*(A+B+!C)*(A+!B+C)*(!A+B+C)
La tabella fuò essere fornita vuota ma ti viene detto "la funzione C0 è caratterizzata dai seguenti MINTERMINI (= per quali configurazioni di ingresso l'uscita vale 1): 1,2,4,7, MINTERINI della funzione C1: 3, 5, 6, 7"

Ritardo massimo (misurato su 1 segnale) se NOT=1ns, AND=2ns, OR=3ns
C0 ha 1 NOT, 2 AND, 2 OR = 1+4+6=11ns
Una porta a N ingressi è implementata da N-1 porte a 2 ingressi.

Semplificare le funzioni.
Consiglio: se ho una funzione con termini dispari, fare in modo che diventi pari. In che modo? Con la proprietà di idempotenza (x=x+x).
G(a,b,c) = !a!b!c+!a!bc+!ab!c
	1)applico idempotenza: !a!b!c+!a!bc+!ab!c+!a!b!c
	2)applico pr.distributiva: !a!b(!c+c)+!a!c(b+!b)
	3)siccome !c+c = 1 e b+!b=1 ho:  !a!b+!a!c = !a(!b+!c)

z = !((A^B)+(C^D)) . Cosa faccio? Prima cosa: ESPANDO lo XOR. A^B = A!B+!AB

Martedì 8 ottobre 2019

Circuiti sequenziali. È così se le sue uscite non dipendono solamente dagli ingressi ma dallo stato, cioè dal comportamento passato.
Una stessa configurazione in ingresso applicata in istanti diversi produrrà un uscita diversa.
u(t) = f(i(t), stato)
Lo stato contiene l'info passato dal circuito.
È bistabile: el. di mem. in grado di memorizzare un bit di informazione.
          ______________
--------->|Circuito    |
ingresso  |combinatorio|------>uscita
      /-->|____________|--------
	  |                        |
	  |stato attuale           |stato futuro
	  |                        |
	  _______________________  |
      |                     |  |
	  | Elementi di memoria |<-/
	  |_____________________|
I bistabili esistono sincroni e asincroni.
	Asincroni: stato cambia ad ogni evento sul segnale di ingresso in qualunque istante di tempo.
	Sincroni: sensibili ad un segnale di controllo di sincronizzazione (il nostro è il clock). Sincronizzazione uscite / transizione di stato avviene solo in corrispondenza di eventi sul segnale di sync (controllo).
		Due tipi di bistabili sincroni: Gated lech e flip flop.
			Gated lech sono controllati.
			Flip flop sono di 2 tipi: master-slave e edge-triggered

I bistabili sono fatti con il bistabile SR asincrono.
Per sapere come funziona bisogna avere a mente la porta logica NOR (tutti 0 in uscita, tranne quando in ingresso ci sono tutti 1).
Il bistabile SR asincrono ha 2 ingressi esterni (S e R), due NOR e due uscite !Q e Q. Se S e R l'uscita rimane quella del passato.
S | R | Q |!Q | (SET, RESET, Q, Q negato)
0 | 0 | Q |!Q | (se Q=1 in partenza, rimane 1; se invece Q=0, Q rimane 0 e Q!=1)
0 | 1 | 0 | 1 | (indipendentemente dall'uscita precedente)
1 | 0 | 1 | 0 | (indipendentemente dall'uscita precedente)
1 | 1 | 0 | 0 | (ha poco senso fare set e reset insieme, ma se lo faccio ha un comportamento indesiderato / non previsto. EVITARE)

Altro modo per rappresentare il bistabile è un diagramma temporale. Sulle ascisse tempo, sulle ordinate R, S e Q.
 ^
.|______         ______ 1
Q|      \_______/       0
.|__             __     1
S|  \___________/  \___ 0
.|        __            1
R|_______/  \___________0
.|
 |---------------------->t

Nei bistabili sincroni nel grafico c'è anche il clock da considerare sull'asse verticale.
Bistabile SR sincrono (latch SR)
Si aggiungono 2 porte AND davanti per il clock
Temporizzato a livello.

R-----|AND)---
clock-/        Qui il resto del grafico è uguale a quello precedente.
      \
S-----|AND)---

C | S | R | Q |!Q|
--|---|---|---|--|
0 | X | X | Q |!Q| (X = don't care)
1 | 0 | 0 | Q |!Q| quando il livello è a 1 tutto il cambiamento passa secondo il comportamento dettato dall'SR asincrono.
1 | 0 | 1 | 0 | 1|
1 | 1 | 0 | 1 | 0|
1 | 1 | 1 | 0 | 0|

Bistabile D sincronizzato

Dove D è il dato che verrà sincronizzato

\
 \D
  \______
   |     |AND)
   |    /
   |C--/
   |   \
   |    \
   \-NOT-|AND)

C|D|Q|!Q
-|-|-|--
0|X|Q|!Q
1|0|0| 1
1|1|1| 0

Ritardo di propagazione
Problema del fenomeno di trasparenza (indesiderato). Per risolverlo utilizziamo i flip-flop.
Vantaggio di usare il fronte anziché il livello del clock

Comandi di ripristino: CLR (clear, imposta a 0 e quello che imposta a 1).
I flip flop sono fatti da 2 o 3 bistabili

Flip-flop D master-slave 
Il master è il primo (principale), lo slave quello in cascata (ausiliario). È una coppia di bistabili sincroni D trasparenti in cascata con clock invertiti; l'insieme dei due non presenta il fenomeno di trasparenza

Edge-triggered D flip-flop
È meno costoso del precedente perché usa una OR
Costo totale: 6 nor + 1 or
Il cambiamento si vede sul fronte di uscita

D C Q !Q
0 1 Q !Q

Sia il master-slave e che l'edge triggered sono identici per quanto riguarda l'uscita

Giovedì 10 ottobre 2019

ACSO esercitazioni, esercizi reti - reti sequenziali
Rete combinatoria
Le uscite dipendono direttamente dagli ingressi
Reti sequenziali
Bistabile SR asincrono
(FPGA)
Esercizio TDE

Martedì 15 ottobre 2019
Architettura MIPS
Prelievo istruzione da memoria e incremento PC->lettura 2 registri->operazioni ALU, che possono essere varie.
Register file, 2 richieste lettura 1 in scrittura
leggi appunti cartacei



-----------------
Seconda parte: SISTEMI OPERATIVI
Martedì 12 novembre 2019
S.O. multitasking o multiprocesso: possono esserci più processi in esecuzione simultaneamente, seppure la CPU è una sola.
Due modi per multitasking: tramite processi o tramite thread
Macchina virtuale
File system alla fine del corso

Il SO è in grado di virtualizzare i processi e far credere loro che occupino interamente le risorse, ma è il SO che le alloca.
Con questa soluzione non si può interagire direttamente con l'HW ma ci si deve affidare alle chiamate di sistema, solitamente integrate in delle librerie.
Il SO non è monolitico ma anche lui è composto da più processi.
Come creare processi?
	-> chiamate di sistema per gestirli
Primitive di gestione processi
Ogni processo ha il proprio PID (Process IDentifier) univoco.
Differenze tra programma e processo?
Processo fatto da 3 parti:
	1) segmento codice (text segment)
	2) s. dati (data) che contiene tutte le variabili globali e statiche, locali sulla pila e dinamiche con la malloc
	3) s. di sistema: contiene dati che servono al SO per gestire il programma in esecuzione
A parte init che non ha un processo padre, tutti gli altri ce l'hanno. Un processo padre può creare i processi figli.
Non c'è alcuna relazione tra fratelli
Per generare un processo figlio esiste la funzione fork(), che crea un clone esatto del padre nel momento in cui viene creato

pid_t fork();	//pid_t è un intero. La funzione restituisce al padre il PID assegnato al figlio, il figlio restituisce 0.
pid_t getpid(); // è una funzione che restituisce a chi la invoca il suo PID
void exit(int code); //funzione di exit termina il programma e restituisce un codice al padre

void main(){
	pid_t pid1, pid2;
	pid1 = fork(); //a questo punto esistono 2 processi con pid1 e pid2. SI distinguono perché il padre in pid1 ha il PID del figlio, il figlio ha 0.
	if(pid1 == 0){ // siamo sicuri che solo il processo figlio eseguirà questa istruzione
		printf("Figlio PID: %d\n", getpid());
		exit(0);
	}
	pid2 = fork();
	if(pid2 == 0){
		printf("Figlio PID: %d\n", getpid());
		exit(0);
	}
	if(!pid1 && !pid2){
		printf("Padre PID: %d\n", getpid()); // non so in che ordine verranno scritte queste istruzioni
		printf("Figlio 1 PID: %d\n", pid1);
		printf("Figlio 2 PID: %d\n", pid2);
		exit(0);
	}
}

Per sincronizzare i processi posso utilizzare la chiamata wait(). Questa istruzione blocca il programma che l'ha chiamata. Cosa fa?
Qunado un figlio termina, il padre viene sbloccato. 

pid_t wait(int *) //il valore resituito è il n PID del figlio terminato. Si passa come parametro un valore intero (moltiplicato per 256) passato dal figlio al padre

Se inserissi due istruzioni di wait tra le printf, saprei l'ordine esatto in cui i processi terminano

if(!pid1 && !pid2){
		printf("Padre PID: %d\n", getpid());
		printf("Figlio 1 PID: %d\n", pid1);
		printf("Figlio 2 PID: %d\n", pid2);
		//qui vanno le 2 wait(), credo 
		exit(0);
}

Esiste anche la funzione waitpid

pid_t waitpid(pid_t pid, int* status, int options) //opzioni irrilevanti (mettiamo a 0)
Con questo il padre aspetta la terminazione del figlio con PID==pid (il primo parametro passato)

La funzione exec permette di creare un figlio che ha il segmento codice e dati differenti da quello del padre, ma uguali a quelli di un file eseguibile.

int execl(char * path, char * arg0, char * arg1, ...) //path è il percorso dove è situato il programma, arg0, ecc... sono puntatori a stringhe che verranno passate come parametri al main del programma. arg0 è il nome del programma e argN è null per indicare che sono finiti i parametri

Il processo zombie è terminato ma non è ancora stato pulito perché aspetta il ritorno dei figli.

Supponiamo che il padre abbia PID=500 e il figlio 1 ha PID 501. Il padre finisce dopo figlio 1 che finisce dopo figlio 2
int main(){
	int i,j,k,stato;
	pid_t pid1, pid2;
	i=10; j=20; k=30;
	pid1 = fork();
	if(pid1==0){
		j++;
		pid2 = fork();
		if(pid2==0){
			k++;
			exit();
		}else{
			wait(&stato);
			exit();
		}
	}else{
		i++;
		wait(&stato);
		exit();
	}
}


I THREAD
Modello dei thread. È nato dopo il multiprocesso.
All'interno di un processo possono essere attivi più thread contemporaneamente (non in esecuzione)
Esistono processi "normali", cioè a singolo thread, oppure multithread che conividono dati e file (parte dei dati e codice intero condivisi) ma una pila diversa. Quindi le variabili locali sono proprie di ogni thread. Ogni thread ha associato uno stato di esecuzione.
Per semplificare definiamo 3 stati del thread:
	1)esecuzione: sta eseguendo operazioni sul processore
	2)pronto: p. per essere eseguito ma il processore è occupato
	3)attesa: quando devo interagire con periferiche (disco fisso, tastiera, mouse, video, ...)

Utilizziamo lo standard POSIX Pthread
Il thread è gestito direttamente dal kernel del SO. Quando il thread va in esecuzione gli viene assegnato un quanto di tempo durante il quale può utilizzare il processore. Se finisce prima bene, altrimenti viene interrotto e accodato

Concorrenza vs parallelismo
Due attività A e B sono sequenziali se è possibile stabilire un ordine di esecuzione A<B o B<A.
A e B si dicono concorrenti se non si possono dire sequenziali
A e B si dicono parallele se non è possibile stabilire un ordine di esecuzione tra le attività di A e quelle di B
Nell'ipotesi di avere un solo processore concorrenza e parallelismo sono la stessa cosa

Se termina il main, terminano i thread, in qualunque stato fossero.
Ogni thread ha il suo threadID, univoco all'interno del processo ma non al suo esterno
Attesa: metodo join. Non ci sono thread padri o figli, c'è la possibilità di aspettare il thread desiderato sapendone il threadID
Terminazione: return. Esiste anche la exit come per i processi
Ogni processo ha il suo thread principale, che è la funzione main, creata automaticamente.
Ogni thread ha la sua pila ma le variabili globali sono in comune

Sintassi funzioni per i thread:
pthread_create(pthread_t * threadID, pthread_t *attr, void * (*start_func)(void *), void * arg)
	Argomenti: threadID, null, start_func, puntatore ad area di memoria che voglio passare al thread
int pthread_join(phtread_t target_thread, void * status)
	Argomenti: chi sto aspettando, var in cui viene scritto valore return

Esempio:

#include <pthread.h>
#include <stdio.h>
void * tf1(void * tID){
	int conta = 0;
	conta++;
	printf("sono il thread n.%d, conta=%d\n", (int)tID, conta);
	return NULL;
}

int main(){
	pthread_t tID1, tID2;
	pthread_create(&tID1, NULL, &tf1, (void *)1);
	pthread_create(&tID2, NULL, &tf1, (void *)2);
	pthread_join(tID1, NULL);
	pthread_join(tID2, NULL);
	return 0;
}

Così l'ordine di esecuzione non si sa. Adesso apporto una modifica:
int conta = 0 diventa static int conta = 0.
Così facendo non ho la certezza dell'ordine di esecuzione dei due thread, ma so che il risultato è ordinato.
Se non avessi messo la join è possibile che la variabile conta non venisse incrementata da nessuno

Mercoledì 13 novembre 2019
Ripasso thread e processi.
Per creare un thread si utilizza la funzione: 
	int pthread_create(pthread_t * thread, const pthread_attr_t * attr, (void *)(*start_func)(void *), void * arg)
					   ^il thread definito in precedenza; ^NULL;									   ^indirizzo arg passato alla func
	int pthread_join(pthread_t thread, void * retval)
										^indirizzo variabile che contiene il valore passato dalla return del thread.
Esempio problemi thread.
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>

int c = 0;

void * th_fun(void * arg){
	int a = 0, b=(int)arg;
	a = b+c;
	c=a*a;
	return (void *)a;
}

int main(int argc, char * argv[]){
	pthread_t th1, th2, th3;
	int d;

	pthread_create(&th1, NULL, &th_fun, (void *)3);
	pthread_join(th1, (void *)&d);
	pthread_create(&th2, NULL, &th_fun, (void *)d);
	pthread_join(th2, (void *)&d);
	pthread_create(&th3, NULL, &th_fun, (void *)d);
	pthread_join(th3, (void *)&d);
	return 0;
}

Cosa succede dopo la riga   a   b   c       d   arg
15, rispetto al main        NE  NE  0       U   U/NE    (NE: non esiste)
10, dopo r.17 (th1)         3   3   9       U   3
18, rispetto al main        U   U   9       3   U
10, dopo istr. 19           12  3   144     3   3
20 (main)                   U   U   144     12  U
10, dopo istr. 21           156 12  156*12  12  12
22                          U   U   156*156 156 U

Problemi se i thread devono utilizzare le stesse risorse. I processi si possono parlare ma quel tipo di comunicazione non è adatta ai thread.
Meccanismi di concorrenza applicabili sia a processi che ai thread. Scopo: ordinare l'accesso alle risorse nel modo giusto, esecuzione deterministica. Problemi di serializzazione e di mutua esclusione

Programmazione concorrente

Serializzazione: evento A deve avvenire prima dell'evento B
Mutua esclusione: gli eventi A e B non possono avvenire concorrentemente
Un programma con thread multipli può non essere deterministica

Marco e Paolo lavorano in due città diverse e Marco deve pranzare prima di Paolo. Come fa? GLi manda un messaggio per mangiare
Marco				Paolo
A1 colazione		B1 colazione
A2 lavoro			B2 aspetta messaggio di Marco
A3 pranzo			B3 pranzo
A4 mess. a Paolo

Per cui A1<A2<A3<A4 e B1<B2<B3. A4<B3 e ne risulta che A3<B3

Esempio di codice delle slides
Variabili condivise tra thread(globali e/o statiche)

Thread A				Thread B
			CODICE C
a1	count++				b1 count++
			CODICE ASM MIPS		
a1	lw $t0, COUNT		b1	lw $t0, COUNT
a2	addi $t0, $t0, 1	b2	addi $t0, $t0, 1
a3	sw $t0, COUNT		b3	sw $t0, COUNT
Sequenze di esecuzione:
a1<a2<a3<b1<b2<b3	count+=2
b1<b2<b3<a1<a2<a3	count+=2
a1<b1<b2<b3<a2<a3	count+=1

Condizione per la concorrenza: operazioni atomiche che vengono eseguite completamente senza interruzioni, altrimenti non vengono eseguite per nulla.

IPOTESI C: tutte le modifiche ad una variabile condivisa NON sono atomiche, pertanto è necessario definire meccanismi che consentano l'accesso alle variabili condivise. Ogni volta che thread diversi modificano la stessa variabile in base al suo valore precedente bisogna garantire che le operazioni su questa variabile costituiscano sequenze critiche in mutua esclusione.


Muuta esclusione (MUTual EXclusion): assicurare che un thread alla volta esegua una determinata attività
Sezione critica: parte del codice che può essere eseguita da un solo thread alla volta in modo atomico
Il costrutto MUTEX è messo a disposizione da pthread per gestire la mutua esclusione
Per bloccare una risorsa esiste il lucchetto: lock, che previene qualcuno di accedere alla risorsa condivisa.
Parole chiave: _lock e _unlock. 
	_lock prima di entrare nella sezione critica dove accedo alla risorsa condivisa
	_unlock all'uscita della sezione critica dopo aver terminato le operazioni sulla risorsa condivisa
MUTEX
def. di una variabile di tipo pthread_mutex_t:
	pthread_mutex_t mutex;
inizializza il mutex
	pthread_mutex_init(&mutex, NULL) //NULL sarebbero gli attributi di default
lock mutex:
	pthread_mutex_lock(&mutex);
unlock mutex:
	pthread_mutex_unlock(&mutex);

Esempio 1a di sequenza critica

Giovedì 14 novembre 2019

ripasso spiazzamento rispetto al global pointer del tema d'esame

Esercizi sui thread
e1)
#include <stdio.h>
#include <pthread.h>

void *tf(void *tID){
    printf("I'm thread n.%d\n", (int) tID);
    printf("I'm thread n.%d\n", (int) tID);
    return NULL;
}

int main(void){
    pthread_t tID1, tID2;
    pthread_create(&tID1, NULL, tf, (void *)1);
    pthread_create(&tID2, NULL, tf, (void *)2);
    pthtread_join(tID1, NULL);
    pthtread_join(tID2, NULL);
    return 0;
}
ideone.com/jSXNKb <- IDE C online
esercizio fibonacci

somma concorrente
problema del lettore-scrittore (produttore-consumatore). e6-e7
deadlock e8

Grafico per i thread 
Quadrati=attori
Cerchi=risorse
i thread puntano sulle risorse quando aspettano che siano liberate

|t1|-->(MB)
 ^      |
 |      ↓
(MA)<--|t2|

terzo esercizio sul problema deadlock

Martedì 19 novembre 2019

Sequenza critica senza mutex (deadlock)
Si assume che una istruzione di alto livello non sia corrispondente ad una sola istruzione atomica in asm.
All'inizio della sezione critica blocco il mutex (lock) e poi lo sblocco con l'unlock
Sequenza critica senza mutex - versione 3: eliminazione deadlock - Peterson
	utilizzo una variabile per eliminare i deadlock
Se l'ordine in cui vengono bloccate le variabili è diverso tra i vari thread, sicuramente si può verificare un deadlock con due o più variabili bloccanti. Condizione per evitare ciò è avere in tutti i thread il blocco risorse fatto nello stesso ordine
Problema: voglio che due thread stampino delle stringhe alternate. Soluzione è un nuovo costrutto: il semaforo. Il semaforo è una variabile intera sulla quale si può operare solo così:
- inizializzato con un valore e poi può essere solamente incrementato o decrementato di 1.
tipo sem_t . sem_init per la creazione, per decrementare sem_wait(&semaforo) che verifica se semaforo == 0, allora viene bloccato
per l'incremento c'è sem_post(&semaforo)
Nello standard POSIX la variabile semaforo non scende mai sotto lo zero
Per implementarli c'è semaphore.h
sem_init(&semaforo, 0, 0)
					^  ^-valore a cui inizializzo il semaforo
					\-pshared (int): If the pshared argument has a non-zero value, then the semaphore is shared between processes

se inizializzo semaforo = 0 il primo thread che arriva si blocca, se lo inizializzo a 1 il primo thread va avanti

Per l'esempio axbycz come sequenza di due thread si risolve così:
th1:					th2:
sem_wai(&sem1);			stampa a;
stampa(x);				sem_post(&sem1);
sem_post(&sem2);		sem_wait(&sem2)
sem_wait(&sem1);
e così via

Questo ci permette di introdurre il paradigma produttore-consumatore
Supponiamo di avere un buffer di un solo carattere. C'è un produttore che scrive ed un consumatore che legge. In mezzo c'è un buffer.
Per farla funzionare correttamente ci devono essere due semafori che indicano lo stato.
Per il consumatore dice quanti caratteri sono presenti sul buffer, per il consumatore il numero di posizioni disponibili da scrivere
Semaforo pieno, se pieno=0 non ci sono caratteri da leggere per il consumatore
Semaforo vuoto per bloccare il produttore. Se vuoto=0 non ci sono posizioni disponibili per scrivere

Generalizzare il produttore-consumatore con il concetto del rendez-vous
Thread A	Thread B
1. a1		1. b1 		<-eseguite subito
2. a2		2. b2

Vogliamo garantire a1<b2 AND b1<a2. abbiamo 2 semafori:
Aarrivato ; Barrivato=0
a1 può essere eseguito, e anche b1 può essere eseguito in qualunque momento. Adesso segnalo che A è arrivato al punto di sincronizzazione e che non può andare avanti se non 

Esecuzione:
Thread A					Thread B
1. a1						1. b1
2. sem_post(&Aarrivato);	2. sem_post(&Barrivato);
3. sem_wait(&Barrivato);	3. sem_wait(&Aarrivato);
4. a2						2. b2

Qualunque sia l'ordine di esecuzione, non c'è deadlock. Se avessi messo prima entrambe le wait e poi le post, ci sarebbe un deadlock. Se avessi messo solo una wait prima di una delle due post, allora ok.
I semafori sono più potenti dei mutex e possono implementarne uno. Un semaforo inizializzato a 1 è un mutex (mutua esclusione).

Il problema della barriera.
Ho un numero T di thread che si devono sincronizzare in un punto (un rendez-vous però con tanti thread).
int count=0; // conta quanti thread sono arrivati al punto di sincronizzazione
	^
	\- accesso in mutua esclusione mutex
sem_t barriera = 0; // finché non sono arrivati tutti quanti i T thread in barriera, impedisce di proseguire.


Com'è fatto all'interno Linux?
Linux è solo il kernel, si basa su UNIX.
A noi intersessa il kernel mode, nello specifico File System, Memory management e process management.
Funzioni di Linux - scheduling dei processi
Parallelismo tra procesi. Linux è un S.O. multiprogrammato time-sharing
a ogni processo è assegnato un quanto di tempo. allo scadere del quanto di tempo il processo viene sospeso dall'esecuzione (preemption) e un nuovo processo può utilizzare il processore.
un processo può essere sospeso dall'esecuzione per sospensione volontaria (es. I/O) oppurea llo scadere del quanto di tempo.
Preemption: il processo viene tolto dalla CPU e dato in carico a qualcun altro.
Distinguere tra user space e kernel space.
Tra hardware e kernel interrupt e DMA, ma questi li diamo per fatti.
Devo dare la possibilità per aggiungere dei moduli kernel per gestire nuove risorse realizzate.
Linux nasce prima dei thread. Come si gestiscono i thread? Sono realizzati, ma l'implementazione?
Si chiamano lightweight processes ma nella norma non sono distinti thread e processi, ma sono genericamente chiamati task.
Il processo normale ha
-PC e SP
-Registri CPU
-Stack
-Stdin/stdout/stderr
-memoria (codice, dati e segmento di sistema)
Il thread ha risorse proprie (PC, reg della CPU, stack e sp) ma memoria condivisa
In linux ci sono Process ID e Thread Group ID per i thread (PID e TGID)
Ad ogni processo è associata la coppia di identificatori <PID, TGID>

La sostituzione di un processo in esecuzione con un altro si chiama _Commutazione di contesto_ o context switch
Con contesto si intende l'insieme di informazioni relative al processo in esecuzione, la tabella di MMU
Context switch vuol dire salvare il contesto in esecuzione tolto e caricare l'altro
I/O bound (eseguono operazioni di I/O e bisogna stare attenti a non penalizzarli) o compute bound (questi sfruttano tutto il quanto di tempo).
Il kernel di linux è not-preemtable, ovvero, quando è in esecuzione un processo del S.O. è sempre proibita la sua preemption.
Questo va bene per sistemi normali, ma per quelli real-time è possibile utilizzare una versione del kernel preemptive.
Ci sono meccanismi per limitare le operazioni che hanno effetto su altri processi
Per inserire il modulo su linux insmod e per rimuoverlo rmmod
Noi consideriamo un modello semplificato di linux, per cui abbiamo funzioni astratte che sono messe in italiano.
Noi facciamo riferimento all'architettura x86-64 a 64 bit, architettura ISA definita nel 2000, evoluzione dell'intel x86, ed usiamo la Long 64-bit

Mercoledì 20 novembre 2019

Ripasso time sharing, context switch.
Tasks: 1 in esecuzione, più tasks pronte e più tasks in attesa.
Modalità di esecuzione: (U)ser e SO=supervisor
Strutture dati per la gestione dei processi
	-descrittore del processo
	-una pila di sistema operativo (sPila) del processo. Esiste una sPila diversa per ogni processo.
Il processo ha due pile: la sPila viene utilizzata quando il processo chiede informazioni al sistema operativo. La uPila (pila utente) serve per variabili, chiamate a funzione, ecc...
Descrittore del processo <linux/sched.h> viene allocata dinamicamente nella memoria dinamica del kernel ogni volta che viene creato un nuovo processo.
struct task_struct{
	pid_t pid;
	pid_t tgid;
	volatile long state;
	void *stack;
	struct thread_struct thread;
	struct mm_struct *mm;
	int exit_state;
	int exit_code, exit_signal;
	struct fs_struct *fs;
	struct files...
}

struct thread_struct{
	unsigned long sp0; //dove inizia in memoria la pila
	unsigned long sp; //dove siamo sulla pila
	unsigned long usersp; //dove è arrivata la pila utente
}
Per leggere sp0 e sp devo fare delle chiamate al SO
Questo era il capitolo 1 (N1) del kernel della dispensa che c'è su beep.
Ora inizia la parte N2: meccanismi hardware di supporto al sistema operativo

Funzioni pop e push per operare sulla pila richiedono solo na istruzione ciascuna
Semplificazioni per chiamata e ritorno di funzione
PUSH rx
POP rx
CALL FUNCT (nel caller)
RET (nel callee)

Strutture dati ad accesso HW. SO può accedervi per impostare valori che governano il funzionamento dell'HW e per leggere valori perconoscere lo stato dell'HW.
PSR (processor status register) contiene U/S, priorità corrente del processo 
Chiamata al SO - SYSCALL
COn l'istruzione SYSCALL, non privilegiata (quindi può essere eseguita in U), viene realizzato un salto al SO e quindi passa alla modalità di esecuzione S. Passaggi:
1. valore incrementato di PC viene salvato sulla pila
2. valore PSR salvato sulla pila (PUSH)
3. nel PC e nel PSR vengono caricati dei valori presenti nel _vettore di syscall_
Linux inizializza il vettore di syscall durante la fase di avviamento del sistema con la coppia: <indirizzo a funzione syscall, ...>
L'istruzione privilegiata SYSRET fa cambiare la modalità di esecuzione da S a U. È l'unico punto di uscita dai servizi del SO.

Il modello della memoria
Lo spazio di indirizzamento potenzialmente disponibile è 2^64 byte.
C'è una parte inutilizzabile che, di fatto, limita lo spazio di indirizzamento utilizzabile a 2^48 byte (256 TB).
Lo userspace contiene la parte inferiore da 0 a 0x7FFF FFFF FFFF FFFF
Il kernelspace ha la parte superiore che va da 0XFFF 8000 0000 0000 fino a 0XFFFF FFFF FFFF FFFF
Entrambe sono limitate a MAX 2^47 Byte ciascuna
La memoria è paginata, le pagine sono di 4kB.
L'inidirzzo della memoria virtuale è fatto da n°di pagina e dda offset nella pagina

Commutazione della pila nel cambio di modo
Per poter commutare dal modo U a S e attivare la sPila è necessaria una struttura dati basata su due celle di memoria: USP e SSP (che in molti casi sono due registri non utilizzabili) per salvare lo user SP e il Supervisor SP. 
Commutazione di pila
Meccanismo di interrupt
Interrupt e gestione degli errori (eccezioni). Spesso la gestione consiste nella terminazione forzata (abort) del programma che ha causato l'errore eliminando il processo.
Interrupt annidati. Vengono eseguiti solo se la priorità del nuovo interrupt è maggiore
Riassunto cambio di modo:
meccanismo di salto|modo di partenza|modo di arrivo|meccanismo di ritorno|modo dopo il ritorno|
-------------------|----------------|--------------|---------------------|--------------------|
salto a funzione   | U              | U            |istruzione di ritorno| U                  |
salto a funzione   | S              | S            |istruzione di ritorno| S                  |
SYSCALL            | U              | S            |SYSRET               | U                  |
interrupt          | U              | S            |IRET                 | U                  |
Interrupt          | S              | S            |IRET                 | S                  |
----------------------------------------------------------------------------------------------|
Interfacce standard e Application Binary Interface (ABI)
regole di invocazione del SO
	n.servizio da invocare: registo rax
	parametri da passare: reg. rdi, rsi, rdx, rd10, rd9, ...
esempio del servizio read()

Terzo set di slide (N3)
Diagramma degli stati di un processo e relative transizioni di stato
In ESECUZIONE: sta occupando la CPU
In ATTESA: aspetta la fine dell'interrupt per andare in ready
PRONTO: aspetta di essere eseguito
Diagramma delle transizioni di stato
Scheduler CFS (Completely Fair Scheduler)
Politica di scheduling
Il context switch è svolto dalla funzione schedule()

Runqueue() è la lista di tutti i processi pronti. È composta da RB: lista di puntatori ai descrittori dei processi pronti (escluso quello corrente in esecuzione); e da CURR, puntatore che punta al descrittore del processo correntemente in esecuzione.
La runqueue è una lista doppia circolare
Esiste anche la waitqueue: una lista contente i puntatori ai descrittori dei processi in attesa di un certo evento
Esiste una waitqueue separata per ogni evento. I processi in una waitqueue saranno risvegliati da una wakeup quando arriverà l'evento specifico. Quando un processo viene risvegliato viene posto nlla runqueue, quelli ancora accodati rimangono lì.
Gestione di USP e SSP nel context switch, ovvero quando sostituisco il processo in esecuzione con un altro.
Esempio: devo commutare P (in esecuzione) con Q (pronto) in modalità U
	1) salvare USP nella sPila si P e nel descrittore usersp
	2) salvare SPcorrente nel campo sp del descrittore
	3) salvare PC nella sPila 
Se invece volessi fare il contrario ricarico quello che ho salvato.
Esempio 2: devo commutare P (in esecuzione) con Q (pronto, ma stava eseguendo il servizio 2) in modalità U
	P esegue una syscall:
		la system_call invoca il servizio s1
	..

Giovedì 21 novembre 2019
Esercizi programmazione concorrente
Cose caricate sul beep
Problema castng da void * a int su macchine 64 bit (void * viene considerato a 64 bit, int a 32)
Per chi vuole fare robe belle coi thread con C c'è la libreria in extra_material.c -foemap

Thread versus processi: vantaggi e svantaggi.
I thread sono più efficienti ed è più comodo scambiare dati tra di essi; d'altro canto i processi sono più protetti perché uno non può danneggiare l'altro, inoltre è possibile il cambiamento di eseguibile. Ricordiamo che un thread è non deterministico.
I semafori
Esempi in acso-so/e1.c e acso-so/e1_1.c . Tempo di esecuzione del programma >=10 secondi
Esercizio di scrittura di codice semaforo - bevuta.c e2.c

Temi d'esame


Martedì 26 novembre 2019
Come il kernel (nucleo) esegue una gestione multiprocesso con una sola CPU
Il processo può essere in modalità utente se lo ha scritto lui oppure supervisore se è svolto per conto del SO.
Per entrare in modalità S (supervisor) si usa la syscall, che è un bit in un registro che viene attivato.
Come si toglie un processo in esecuzione come S? O aspetto che si metta in attesa - e quindi c'è una salvataggio di contesto - oppure scade il suo quanto di tempo a disposizione, quindi salva il contesto e poi riprende l'esecuzione.

I processi hanno sempre due pile: quella U e quella S. Quando il processo è in modalità U, la sPila è vuota. 
Quando si passa da U a S c'è una syscall e si salva il valore corrente del registro SP che punta alla pila U in USP e carica in SP il valore contenuto in SSP, che è sp0 (contenuto nel descrittore del processo), ovvero la base della pila S dato che è vuota. Salvataggio sulla sPila PC, PSR e carica in PC e PSR il valore presente nel vettore di syscall e quindi passa in modo S.

_Commutazione di contesto_
Il processo viene tolto dalla CPU, ma prima di ciò è necessario il salvataggio di contesto.
USP viene salvato sulla sPila e il valore corrente del registro sp (punta alla cima della pila di sistema spila) viene salvato nel campo sp del descrittore del processo.
A questo punto lo scheduler sceglie un processo che carica il suo sp.

_Gestione degli interrupt_
Interrupt è un evento asincrono che non ha nulla a che vedere col processo in esecuzione al momento. È gestito all'interno del processo in esecuzione anche se non è roba sua. 
Vettore di interrupt indica l'indirizzo di partenza della risposta all'interrupt
Come funziona l'interrupt?
	1. interrompe il processo che funziona in modalità U oppure un servizio di sistema invocato dal processo correntemente in esecuzione oppure un interrupt con priorità minore
	2. ...

Gestione dello stato d'attesa: waitqueue
Diversi tipi di attesa: I/O, sblocco del lock (MUTEX o semaphore), scadere di un timeout.
Una waitqueue è una lista che contiene i descrittori dei processi in attesa di un certo evento.

Attesa esclusiva e non esclusiva
In alcuni casi conviene risvegliare tutti i processi presenti nella coda associata ad un evento (es. processi che attendono la terminazione di un'operazione su disco). 
In altri casi conviene risvegliarne uno solo (es. molti processi in attesa della stessa risorsa bloccata). (non esclusiva)
Esistono due funzioni:
wait_event_interruptible() e wait_event_interruptible_exclusive()
I processi in attesa esclusiva sono inseriti alla fine della waitqueue

_I segnali (signal)_
Sono un avviso asincrono inviato dal SO oppure da un altro processo.
Es. SIGKINT (CTRL+C) (=/= sigkill), SIGSTP (CTRL+Z) (=/= sigstop).
Sono numerati da 1 a 31 e da un nome simbolico abbastanza autoesplicativo
Il segnale causa l'esecuzione di un'azione da parte del processo che lo riceve. 
Può essere svolto solo se il programma è in modalità U di esecuzione.
se il signal viene inviato ad un processo in modalità S si aspetta che rientri.
Se il signal viene inviato ad un processo in stato di pronto si aspetta finché il processo non arriva in esecuzione
Se il signal viene inviato ad un processo in stato di attesa in waitqueue ci sono 2 casi:
	1. se l'attesa è interropibile il processo viene risvegliato da signal e poi entra in funzione il segnale
	2. se l'attesa non è interrompibile

Per risvegliare un processo c'è la funzione wake_up(wait_queue_head_t * wq) che risveglia tutti i task in attesa non esclusiva e un solo task in attesa esclusiva.
Cosa fa? Mette lo stato a pronto e li elimina salla waitqueue e li mette nella runqueue.
se un nuovo task aggiunto alla runqueue ha maggiori diritti di esecuzione rispetto a quello corrente il flag TIF_NEED_SCHEDULER viene impostato a 1 da wake_up.

Esempio di una stampante che stampa un carattere per volta.
Un processo che richiede un servizio di write (funzione di libreria glibc) di N caratteri. Il SO prende in carico la richiesta usando la syswrite e fa richiesta di scrittura alla periferica. I caratteri da inviare vengono spostati dll'area di memoria del processo a quella di sistema. Il servizio di sistema chiama la wait_event_interruptible e sospende il processo spostandolo nella coda.
Quando la periferica ha finito, segnala che ha terminato inviando un interrupt e questo fa svegliare il processo in attesa di quell'evento spostandolo nella runqueue e quando torna in esecuzione si chiede se ha terminato di eseguira la stampa di N caratteri oppure se ha terminato.
La wakeup è un interrupt (asincrono).

Esempio di attesa esclusiva: implementazioen dei mutex.
Linux utilizza un meccanismo detto futex (Fast Userspace Mutex) (non peterson) per realizzare i mutex in maniera efficiente.
Due componenti del futex: una variabile intera nello spazio U e una waitqueue WQ nello spazio S
Devo garantire che l'incremento e il test siano svolti in maniera atomica in spazio U 
	se il lock può essere acquisito l'operazione ritorna senza bisogno del SO
	se è bloccato si invoca un syscall chiamate sys_futex() con il parametro wait (la unlock invece passa il paraetro wake)

La preemption
dato che il nucleo è non-preemptive
	-non viene eseguita immediatamente una commutazione di contesto quando il sistema scopre che un task in esecuzione dovrebbe essere sospeso e portato in stato di pronto ma viene impostato a 1 il flag TIF_NEED_RESCHED. Successivamente, al momento opportuno, questo flag causerà la commutazione di contesto. Una commutazione viene svolta durante l'esecuzione di una routine del SO solamente alla fine e solamente se il modo al quale la routine sta per ritornare è il modo U. Ovvero: il SO prima di eseguire una IRET o una SYSRET che lo riporta al modo U e se necessario esegue una preemption.

Altri tipi di attesa
	Variante di wakeup che è wakeup_process(task_struct * processo) per risvegliare solo un processo. (es. il padre aspetta che il figlio termini con la join di un thread. Quindi la exit() risveglia il padre del thread.)
	Attesa di un timeout che definisce una scadenza temporale.
	La variabile jiffies registra il numero di tick del clock avvenuti dall'avviamento del sistema (i jiffies dipendono dalla frequenza del clock).
	Il servizio sys_nanosleep svolge le seguenti azioni: sposta il processo da esecuzione in attesa. Dopodiché chiama schedule_timeout con un parametro in jiffies. Questa funzione dice qual è il processo che sta aspettando, aggiunge il nuovo timer, definisce quale processo verrà eseguito, ... . Questo schedule_timeout viene messo nella coda dei timer. Quando il processo torna in esecuzione, il timer non serve più e viene eliminato con delete_timer(&timer).
	Risveglio dal timer con wakeup: il controllo della scadenza dei timeout non può essere svolto ad ogni tick per ragioni di efficienza. La soluzione è complessa.
La schedule è l'unica funzione che inizia con un processo e termina con un altro, ocsì come la reschedule.

Funzioni dello scheduler utilizzate dalla gestione dello stato
	schedule()
		1)controllo se lo stato corrente è quello di attesa
		2)context switch
	check_preempt_curr()
		(utilizzata quando faccio la wakeup)
		1) controlla se il task deve essere preemted, in tal caso attiva flag diritto a 1
	enqueue_task()
	dequeue_task()
	resched()
		pone TIF_NEED_RESCHED a 1
	task_tick()
		scheduler periodico, invocata dall'interrupt del clock e aggiorna vari contatori e determina se il task deve essere preempted perché è scaduto il suo quanto di tempo.

Pseudocodice della funzione void wait_event_interruptible(coda, condizione){
	// costruisci un elemento della waitqueue che punta al descrittore del processo corrente. Aggiungi il nuovo elemento alla waitqueue poni i flag a indicare se è esclusivo o non esclusivo in base a xxx. Infine poni stato del processo (current->state) a ATTESA.
	schedule();
	//quando il processo riparte rimuovi il processo corrente dalla waitqueue.
}

Pseudocoice della wakeup
void_wakeup(wait_queue_head_t * wq){
	//per ogni descrittore puntato da un el. di wq
	{
		cambia lo stato a pronto
		enqueue();
		eliminalo dalla waitqueue
		se il flag è esclusivo break
		...
	}
	...
}
Pseudocodice di R_int_clock(...){
//gestisce i contatori di tempo reale
}

void R-int_evento(){
	//cose realtive all'evento
	wake_up(head_event_queue);
	if(modo di rientro è U ed è urgente)
		schedule();
}

Codice assembly nei sorgenti linux:
La funzione schedule() invoca la funzione context_switch() che a sua volta contiene la macro assembler #define switch_to(prev, next).
L'operazione centrale consiste nella sostituzione della sPila del processo uscente con la sPila del processo nuovo che nel x64 consiste nelle seguenti 2 istruzioni:
	movq %rsp, threadrsp(%prev)
	movq threadrsp(%next), %rsp
Ovvero passo da una pila all'altra e il processo viene riportato nella schedule
È possibile inserire codice assembly nel codice C.

Gestione della concorrenza nel nucleo
Cause di concorrenza:
	a. esistenza di molte CPU che eseguono in parallelo
	b. la sospensione di un'attività a causa di una commutazione di contesto, con partenza di nuova attività

PID 1 : init. È un processo idle che non muore e rimane sempre lì finchè non c'è più nessun processo da eseguire e tiene eseguito il processore.
init è un processo normale, in modalità U che però non ha un processo padre.
il processo 1 crea un processo per ogni terminale sul quale potrebbe essere eseguito un login (leggendo il file (initab).
Questo processo esiste sempre, finché non spengo la macchina.
Il processo idle ha priorità infima e non ha mai bisogno di sospendersi. La sua esecuzione può sospendersi quando si verifica un interrupt

Tutte le funzioni della glibc chiamano la wrapper che chiama la syscall(servizio_richiesto). La syscall() chiama l'istruzione SYSCALL che fa passare dalla modalità U a quella S. La quale a sua volta chiama la system_call che legge il numero del servizio da %rax e invoca la sys_xxx.
La funzione syscall() è dichiarata nel modo seguente:
long syscall(long n_servizio, param_del_serv);

Esempio di invocazione del servizio read()
read(fd, buf, len) -> syscall(sys_read, fd, buf, len) -> syscall() //carica qualcosa nei registri ed esegue SYSCALL

Programma utente | glibc     | glibc    |
-----------------|-----------|----------|
funct()          |read(...)	 |syscall()
.                              rax = ...
.                              ...
.                            | SYSCALL  |->chiama la system_call(...) che chiama la sys_read(...), tutto questo cambiando modalità di esecuzione da U a S.
x_read(...)      | syscall(sys_read)|   |

Quindi:
programma utente chiama la sua funzione che chiama la sua read che chiama la read della glibc che chiama la funzione syscall() che chiama la SYSCALL che chiama la system_call del SO che chiama la sys_read che interagisce con la wait_event_inter(..) che chiama la wait_event_interr() con dentro la schedule. Il cambiamento della pila è importante perché c'è nel tema d'esame.

Mercoledì 27 novembre 2019

Quando un processo ha bisogno del SO per I/O, thread invoca una syscall(). syscall()->SYSCALL->system_call
wakeup sveglia tutti quelli bravi e uno di quelli egoisti, wakeup_process ne sveglia uno solo
enqueue() ->sposta il processo nella runqueue
mutex_lock o sem_wait ->syscall(sys_futex, wait, ...) se lock è bloccato
mutex_unlock o sem_post->syscall(sys_futex, wakeup, ...)
sys_nanosleep->schedule_timeout->add_timer(&timer); schedule(); delete_timer();
controlla_timer->fa la wake up se è scaduto il tempo
La IRET è quella che ti fa tornare in modalità U dalla S
Per linux non c'è differenza tra thread leggeri e "pesanti" (processi)
La funzione clone() permette più operazioni della fork() e della pthread_create().
sys_clone implementa clone() e fork(). pthread_create() implementa clone().
La funzione clone() ha 3 flag: CLONE_VR (condividono area di memoria), CLONE_FILE (tabella file aperti condivisa) e CLONE_THREAD per definire un thread.
La sys_clone assomiglia alla funzione fork() per cui a differenza della clone() non ha il parametro fn e il figlio riprenderà l'esecuzione all'istruzione successiva come in fork().
Attenzione al parametro child_stack: se è 0 il figlio lavora sulla pila che è una copia fisica della pila del padre posta allo stesso indirizzo virtuale, se è !0 il figlio lavorerà su una pila posta all'indirizzo di child_stack.
Realizzazione di clone()
È richiesto del codice assembler per la sua implementazione della pila
clone(void (*fn)(void *), void *child_stack, int flags, void *arg, ...)
Eliminazione dei processi
	sys_exit(): cancella un singolo processo
	sys_exit_group(): cancellazione di tutti i processi di un gruppo
la sys_exit_group() manda un signal a tutti i processi del gruppo e poi chiama la sys_exit().
La sys_exit() rilascia la memoria del processo, elimina il processo dalle code che aveva in sospeso, rilasciare tutti i files e invoca la wake up del padre per poi chiamare la schedule.

Accesso allo spazio U del sistema operativo
Linux ofre una serie di macro assmbler per questo Linux/arch/x86/include/asm/uaccess.h
Esempio get_user(x, ptr) dove x è la var del so su cui salvare il ris. e ptr è il ptr alla var sorgente nello spazio di memoria U.
Esiste analogamente put_user(x, ptr)
sys_execve -> esegue la mutazione di codice

_Lo scheduler_
Decide quali task eseguire e per quanto tempo eseguirle.
È il pezzo più importante del SO perché decide come impiegare la CPU.

	Politica di scheduling equa (round robin)
		tutti i task vengono schedulati a turno per lo stesso tempo di esecuzione
		Questa implementazione ha dei problemi: non è detto che tutti utilizzino il proprio quanto di tempo; non si possono distinguere i processi per priorità.
		
Classi di scheduling (diverse, ordinate per priorità): 
	task real time (o hard realtime);
	task semi real time (o soft realtime) (es. streaming video);
	task normali:
	\-> t. I/O bound; (si autosospendono frequentemente perché devono agiornare l'i/o (es. interfaccia grafica))
	\-> t. CPU bound. (tipo un compilatore, che non facendo i/o può utilizzare la cpu appieno)
		Task normali si dividono in due: task i/o bound, che si autosospendono frequentemente perché devono agiornare l'i/o (es. interfaccia grafica); e task cpu bound, tipo un compilatore, che non facendo i/o può utilizzare la cpu appieno.

	Nel descrittore del task "const struct schedule * sched_class" rappresenta la classe di scheduling che gestisce il task.
	Lo scheduler è l'unico gestore dei task in stato di pronto, ossia l'unico gestore della runqueue

I processi normali sono normati dal CFS: Completely Fair Scheduler.
In questo momento in linux esistono 3 classi di scheduling:
	SCHED_FIFO
	SCHED_RR
	SCHED_NORMAL
Quindi per ogni task usa l'algoritmo che gli appartiene: FIFO per i realtime (alta priorità) , RR e normal ha priorità infima ma è quella che è regolata dal meccanismo più complesso.

pick_next_task() decide quale task mandare in esecuzione. Se non ce n'è nessuno, mando idle (PID 1).
Priorità statica va da 1 a 99 e non cambia finché non termina

per i processi SCHED_FIFO l'esecuzione va avanti finché esso stesso non si mette in wait oppure termina, per SCHED_RR c'è un quanto di tempo uguale per tutti ciclica
Cosa si fa per i processi di classe NORMAL?
	1. determinare ragionevolmente la durata del quanto di tempo (fissa o variabile) (se troppo lungo sys poco responsivo, se troppo grande sys sovraccarico)
	2. assegnare un peso a ciascun task
	3. permettere ad un task rimasto a lungo in wait di tornare rapidamente in esecuzione ma senza favorirlo troppo

CFS
Chiamiamo il peso task LOAD e gli assegniamo il valore L0 (che è il peso iniziale)
Definiamo il numero dei task nella runqueue NRT, che è sempre >=1 (idle è sempre pronto).
Definiamo un periodo di scheduling PER durante il quale i processi non si autosospendono
PER = max(LT, NRT*GR)
LT = latenza di default = 6ms
GR = granularità di default = 0,75ms
Quindi finché NRT non è 8, all'inizio LT è il più grande
Ad ogni task associo un quanto di tempo, che chiamo Q = PER/NRT.
    PER
Q = ---. 
    NRT
Meccanismo base di CFS - gestione della runqueue
RB è runqueue. 
1. Il task in testa a RB diventa corrente (CURR)
2. CURR viene eseguito finché non scade il quanto Q
3. CURR viene sospeso e messo in coda a RB
4. goto 1
I task sono eseguiti a turno per esattamente PER/NRT ms.
Il periodo di schedulazione PER è una sorta di finestra scorrevole nel tempo.
...
Durata del quanto in funzione del peso del task
Definiamo un parametro chiamato t.LOAD che è il peso dello specifico task; definiamo poi RQL la sommatoria di tutti i pesi dei task che abbiamo nella runqueue.
t.LC è un coefficiente di load
t.LC = t.LOAD/RQL
t.LOAD = t.LC*RQL
t.Q = PER*t.LC

Se tutti i task hanno t.LOAD = L0, Q=PER*LC (LC = t.LOAD/RQL ma RQL = NRT*L0), quindi Q=(PER*L0)/(NRT*L0) = PER/NRT

Lo scheduler CFS usa il Virtual RunTime (VRT) per ordinare i task nella runqueue
Il VRT è una misura virtuale del tempo di esecuzione consumato da un processo, basata sulla modifica del tempo reale di coefficienti opportuni.
La RB viene ordinata in base al valore del valore del VRT per ogni processo.
Adesso ogni volta che un processo va messo nella RB lo si mette ordinato in base al VRT

(Ri)calcolo del Virtual RunTime VRT di un task
	variabili:
		SUM   = tempo totale di esecuzione del task
		DELTA = durata del quanto di tempo consumato dal task in esecuzione
		t.VRTC = 1/t.LOAD è il coefficiente di correzione di VRT (vrt_coeff)

	calcolo
		SUM  = SUM + DELTA
		VRT  = VRT + DELTA * VRTC
		VRTC = L0/LOAD
		VMIN = VRT minimo tra tutti i VRT dei task nella runqueue (RB). VMIN deve crescere monotonicamente. Per ora VMIN = min(CURR VRT, LFT.VRT) dove CURR.VRT è il processo correntemente in esecuzione e LFT.VRT è il primo processo in coda, ovvero quello con VRT minimo.
		t.VRT = t.VRT+DELTA*t.VRTC

funzione tick() con virtual runtime
tick(){
	DELTA = NOW - CURR->START;
	CURR->SUM = CURR->SUM + DELTA;
	CURR->VRT = CURR->VRT + DELTA * CURR->VRTC;
	CURR->START = NOW;
	VMIN = min(CURR->VRT, LFT->VRT);
}
//se c'è bisogno, rischedula
In pratica il VRT viene ricalcolato ad ogni tick del real-time clock

Esempio 1: task senza attesa
Condizioni iniziali (da trovare:)
	t.LC  = t.LOAD/RQL = 1/3   = 0,33ms
	VRTC  = L0/LOAD    = 1/1   = 1ms
	Q     = PER*LC     = 6*1/3 = 2ms
Ora supponiamo di avere un periodo di 7 secondi per vedere cosa succedea
Dopo 2 ms scade il quanto e aggiorno il processo in esecuzione
SUM = 10 + 2 = 12
VRT = 100 + 2 * 1 = 102

Esempio 2 

Giovedì 28 novembre 2019
esercitazione sul kernel linux

Martedì 3 dicembre 2019
Scheduler processi/thread normali
Ripasso lezione di mercoledì
Sommatoria pesi relativi è RQL = sommatoria dei t.LOAD
La runqueue ordinata con virtual runtime 
VRT = VRT + DELTA * VRTC
VRTC = L0/LOAD
VMIN = min(CURR.VRT, LFT.VRT) //curr.vrt è il processo in esecuzione e lft.vrt è il primo processo in coda
pseudo codice di pick_next_task_fair()
Calcolo VRT per un processo risvegliato:
	tw.VRT = max(tw.VRT, VIM-LT/2) //LT di default è 6 ms
	VIM = max(VMIN, min(CURR.VRT, LFT.VRT))

Esempio 3: task con attesa e risveglio
Condizioni inizali
RUNQUEUE	NRT	PER		RQL		CURR	VMIN
			3	6,00	3,00	t1		100,00
TASKS:		ID	LOAD	LC		Q		VRTC	SUM		VRT
	CURRENT	t1	1       0,33    2,00    1,00    10,00	100,00
	RB TREE	t2	1       0,33    2,00    1,00    20,00   100,50
			t3	1       0,33    2,00    1,00    30,00	101,00
Evento 1: t1: WAIT at 1.0
EVENT	TIME	TYPE	CONTEXT	RESCHEDULE
        1,00    WAIT    t1      true
RUNQUEUE	NRT	PER		RQL		CURR	VMIN
			2	6,00	2,00	t1		100,50
TASKS:		ID	LOAD	LC		Q		VRTC	SUM		VRT
	CURRENT	t2	1       0,33    2,00    1,00    10,00	100,00 <-qui cabiano le cose
	RB TREE	t3	1       0,33    2,00    1,00    20,00   100,50 <-qui idem
___
	WAITING	t1	1,0		0,33	2,00	1,00	11,00	101,00
Evento 2: scade il quanto di tempo al tempo 4
Evento 3: wakeup di t1 al tempo 5.0
EVENT	TIME	TYPE	CONTEXT	RESCHEDULE
        6,00    WAKEUP  t3      true
RUNQUEUE	NRT	PER		RQL		CURR	VMIN
			3	6,00	3,00	t1		103,00
TASKS:		ID	LOAD	LC		Q		VRTC	SUM		VRT
	CURRENT	t1	1       0,33    2,00    1,00    10,00	103,00<-|\
	RB TREE	t3	1       0,33    2,00    1,00    20,00   103,50<-|--ovviamente qui i valori sono sballati
			t2	1       0,33    2,00    1,00    30,00	103,50<-|/
Evento 4: al tempo 8 cambia il contesto
Evento 5: t3 WAIT at 3.0 (2+1)
Evento 6: t3 rientra in coda di esecuzione con la wakeup
Evento 7: cambio di contesto al tempo 12 ed entra t2

Esempio 4: task con attesa (breve) e risveglio 
assegnamento del peso ad un task: nice
nice value di default è 0 ma può andare da -20 a +20
Riassunto delle regole nella slide 66

Fine slide kernel.
-----
M2 - Organizzazione della memoria virtuale
Con l'architettura x64 lo spazio di dindirizzamento potenziale è 2^64 B con indirizzi virtuali a 64B
Lo spazio di indirizzamento virtuale utilizzabile è 2^48 byte -> 256TB suddiviso in due sottospazi di modo U ed S ambedue da 2^47 Byte, cioè 128 TB.
Lo user space va da 0 a 0x0000 7fff ffff ffff e il kernel da 0xffff 8000 0000 0000 fino a 0xffff ffff ffff ffff. La parte restante è detta area non canonica (non-canonical area).
Considero un eseguibile: il codice del programma inizia a 0x0000 0000 0040 0000 e i dati iniziano da 0x60 0000. Le pile per i thread vengono create in un'area che inizia all'indirizzo 7f7 ffff ffff e cresce verso gli indirizzi bassi (area T)
area M: condivisone tra processi di files e librerie dinamiche condivise
area D: dati allocati dinamicamente
la pila del programma sarà P, i dati statici (S), costanti per la rocazione dinamica (K), il codice del programma sarà (C)
Alcune aree sono uniche, es. C,K,S ma non M, T.
Definizione di area virtuale (vm_area_struct) dentro a Linux/include/linux/mm_types.h
Backing store segment (BSS): un'area virtuale di memoria può essere mappata su file. Se non lo è diventa ANONYMOUS
task_struct file: /bin/gonzo -> mm_struct -> mmap -> vm_area_struct

Due tipi di memoria virtuale:
Mapping basato su file -> possiedono un Backing store (BSS)
	pagine di codice
	librerie
	file di dati
	dispositivi di I/O
Mapping anonimo
	pila
	heap
	pagine copy on write
Questi due tipi di memoria utilizzano meccanismi diversi per l'allocazione delle pagine e lo swapping
Esempio cat /proc/NN/maps (dove NN è il pid del processo)
output: file diviso in colonne. Esempio:
start-end memory addresss, permissions, offset, device, i-node, file name
7fff7bca7000-7fff7bcc8000 rw-p 00000000 00:00 0                          [stack]
permessi linux: rwxp. p = private (copy on write)
Algoritmo di base di gestione dei page fault.
QUando la MMU genera un interrupt di page fault per una pagina virtuale NPV viene attivata la routine di risposta Page Fault Handler:
se NPV non appartiene alla memoria virtuale del processo
	page fault
se ...
	page fault
altrimenti
	...
Flag di Grows down è assegnato alla pila, che cresce dall'alto verso il basso
Linux crea sempre 34 pagine di pila e l'ultima è sempre vuota
La memoria dati deinamica (heap) del programma viene incrementata così:
il C ha la funzione malloc che utilizza una funzione del SO che si chiama brk() e sbrk().
void * sbrk(intptr_t incremento)
Cosa che sbagliamo in ogni tema d'esame in slide 27
creazione di un nuovo processo con la fork->il figlio è un'immagine del padre ma non alloco della memoria fisica
Il processo padre si alloca una nuova pagina, il figlio si becca quella vecchia del padre
quando uno dei due processi cerca di scrivere in memoria -> duplicazione della pagina (copy on write)
Chi chiede la scrittura si becca la nuova pagina 
Gestore delle violazioni di pagina (Page Fault Handler) e duplicazione della pagina
La MMU ha una cache con le pagine recenti che si chiama TLB = Translation Lookaside Buffer
TLB è una cache con le ultime pagine a cui ho fatto accesso
TLB tiene traccia del dirty bit che indica se la pagina è stata scritta o meno
Faccio la exit con conseguente deallocazione, context switch e svuota il tlb.

I thread condividono aree virtuali e tabella delle pagine del processo padre
Linux alla creazione di ogni thread alloca un'area di tipo T di 2048 pagine, 8 MiB, per ogni pila di thread
Linux inserisce una pagina in sola letturacome area di interposizione tra ogni pila come protezione
La pila del primo thread inizia logicamente al NPV 7FFF F77F F e si sviluppa verso indirizzi più bassi.
VMA possono essere classificate in base a due criteri:
	mappate su file o anonoime
	shared o private
Consideriamo 3 tipi di aree: SHARED e mappate su file, PRIVATE e mappate su file, ANONYMOUS e PRIVATE.
Creazione di una VMA da programma utente:
#include <sys/mman.h>
void *mmap (void *addr, size_t length, int prot, int flags, int fd, off_t offset);
--------
Mercoledì 4 dicembre 2019
Memoria virtuale (continua)
Aree virtuali di memoria (VMA)
	(C) area di codice *
	(K) costanti di allocazione dimanica *
	(S) dati statici *
	(D) dati dinamici +
	(T) pile dei thread +
	(N) file mappati in memoria (memory-mapped files) *
	(P) pila o stack +
* = mappata su file
+ = anonima

Aree mappate su file.
Paged cache si usa per non ricorrere sempre al disco.
Paged cache contiene una tabella contente tutte le pagine fisiche utilizzate.
La page cache è strutturata così: identificatore del file e offset su cui è mappata, ref_count e dirty bit
Ref_count è il contatore che conta il numero di processi che stanno utilizzando una pagina in cache
^Questo in lettura, ma in scrittura?
	-La pagina fisica viene modificata -> dirty_bit = 1
	-Tutti i processsi che mappano tale pagina vedono immediatamente tutte le notifiche
	-La pagina modificata verrà scritta su disco una volta sola al termine dell’utilizzo.
Scrittura di un VMA shared mappata su file:
	base = mmap (mapaddress1, PAGESIZE*3, PROT_READ | PROT_WRITE, MAP_SHARED, fd, PAGESIZE);
Scrittura di un VMA PRIVATE mappata su file
Meccanismo di Copy-on-Write:
• Le pagine delle VMA di tipo scrivibile vengono abilitate solo in lettura
• Quando un processo P scrive su una di queste pagine (NPV) si verifica un page fault per violazione di protezione
• Il Page Fault Handler alloca una nuova pagina fisica (NPF), copia in questa nuova pagina di tipo ANONYMOUS il contenuto della pagina che ha generato il Page Fault
• Pone nella Tabella delle Pagine la corrispondenza NPV – NPF e modifica il diritto di accesso W
Nell'esempio due della slide pz non viene inserito nel page cache index in quanto anonimo e privato

Liberare la	page cache
Il file viene eliminato solo se si tratta di un file privato (tipo pz dell'esempio di prima) oppure se la memoria è piena.
Pagine in Page Cache non vengono liberate neppure quando tutti i processi che le utilizzavano non le utilizzano più
• Linux applica il principio di mantenere in memoria le pagine lette da disco il più a lungo possibile, per evitare successivi accessi a disco se richiesti nuovamente
• Le pagine in Page Cache vengono liberate in base alla politica di gestione della memoria quando si arriva a una situazione di memoria quasi piena
• In questo caso vengono salvate sul file del disco (backing store)

Cosa succede alle aree anonime (quindi non mappate su file)?
Le aree di tipo anonymous non hanno un file associato, quindi non alloca memoria fisica. Le pagine virtuali sono tutte mappate sulla ZeroPage (pagina con tutti 0 del SO). 
Se effettuo lettura trovo tutti 0, se provo la scrittura di attiva la copy-on-write
Le pagine anonime se devono essere scaricate dalla memoria vengono salvate in un file chiamato SWAP FILE

Esempio di simulazione della memoria
Indirizzo iniziale del codice: 0x401324
0x40 0000 è dove inizia l'area del codice
0x40 1000 è dove c'è il main, il codice è in questa pagina con offset 0x324

Esercizi sulla memoria che non sto seguendo
Fine slides M2
Gestione della memoria fisica del SO
	Fin'ora abbiamo visto un allocazione di pagine a grana fine (es. malloc nella heap)
	Possiamo però pensare ad una allocazione a grana grossa: grandi porzioni di memoria (brk nella stack)
Esiste una disk cache, che in realtà sta sulla memoria primaria
-----
Martedì 10 dicembre 2019
Gestione della memoria fisica
Bisogna tenere una paged cache in una frazione della memoria.
Page recaliming avviene quando la memoria disponibile è poca.
	Se la pagina è stata letta e mai modificata la si libera, altrimenti deve essere scritta su disco prima di essere resa disponibile
Operazioni di deallocazione:
	1. Scaricamento di molte pagine dache non utilizzate dai processi, se non basta, vedi 2.
	2. Alcune pagine dei processi vengono scaricate. Se non basta usa 3.
	3. Out Of Memory Killer (OOMK)
"free -m" su linux consente di vedere l'occupazione della memoria (-m sta per megabyte)
total è tutta la memoria fisica a disposizione, used è quella utilizzata, free è quella ancora utilizzabile, buffers e cache è la quantità di memoria utilizzata per i buffer/cache ed è considerata disponibile.
/proc/meminfo riporta info sulla memoria. La cache è il maggior consumatore di memoria (cache e buffer sono simili, ma i buffer sono fatti a blocchi, principalmente per i/o)
Allocazione della memoria fisica
	a grana piccola: singole pagine
	a grana grossa: usa pagine contigue, preferito da linux
Buddy system.
	La memoria viene divisa in grandi blocchi
Deallocazione della memoria fisica
	La quantità di memoria libera quando scende sotto un livello critico viene usato il PFRA.
	Problemi:
		Quando e quante pagine è necessario liberare
			parametri: 
				freePages
				requiredPages
				minFree: n pag min libere sotto il quale non si vorrebbe scendere
				maxFree: n.pagine libere al quale PFRA ...
			Invocazione del PFRA:
			.diretta: da parte di un processo che richiede requiredPages di mem se (freePages - requiredPages) < minFree
			.periodica: attivata dal kernel swap daemon (kswapd), invoca il PFRA se freePages<maxFree
			PFRA deterina n pagine da liberare (toFree) con l'obiettivo di riportare sempre il sistema ad avere maxFree pagine libere
			toFree = maxFree - freePages + requiredPages
		Quali pagine liberare
			ci sono diversi tipi di pagine:
				pagine non scaricabili: SO, sPila, ...
				pagine mappate sul file eseguibile dei processi che possono essere scaricate senza mai riscriverle (codice, costanti)
				pagine che richiedono l'esistenza di una swap area su disco per essere scaricate (anonime): pagine dati, pagine della pila (modo U), pagien dello heap
				pagine mappate su file: pagine appartenenti al buffer/cache
			LRU list sono 2 liste globali che collegano tutte le pagine appartenenti ai processi.
				Active list: pagine che sono state accedute di recente e non possono essere scaricate
				Inactive list: pagine inattive da molto tempo e candidate per essere scaricate
			Entrambe le LRU sono tenute in ordine di invecchiamento (giovani davanti, vecchi dietro).
			x64 non tiene traccia del numero di accessi alla memoria, per cui linux realizza un'approssimazione basata sul bit di accesso A presente nella PTE della pagina, che viene posto a 1 dall'x64 ogni volta che la pagina viene acceduta e posto a 0 periodicamente dal SO.
	Il meccanismo di swapping. Operazioni swapout e swapin per liberare e ricaricare pagine in memoria
	Spostamento delle pagine tra le due liste LRU (active e inactive):
		ad ogni pagina viene associato il flag ref (referenced) oltre al bit di accesso A settato dall'hw
	Funzione controlla_liste segue una scansione delle due che eventualmente sposta alcune pagine dalla active list alla inactive list
	Da attivi a inattivi in coda, viceversa il contrario
	
	Algoritmo di controlla_liste
		se a==1
			azzera a
			se ref==1, sposta P in testa alla active
			se ref==0 pone ref=1
		se a==0
			se ref==1, pone ref=0
			se ref==0, sposta P in testa alla inactive con ref=1
nelle 2 liste le lettere maiuscole indicano ref=1, quelle minuscole ref=0
Esercizi di cui non si capisce nulla per due ore
Meccanismo di swap e regole
fenomeno di thrashing 
– il sistema continua a deallocare pagine che vengono nuovamente richieste dai processi,
– le pagine vengono continuamente scritte e rilette dal disco e nessun processo riesce a progredire fino a terminare e liberare risorse

Ultima parte che ci rimane sulla memoria è come viene gestita la tabella delle pagine che faremo domani, inizieremo un esericzio che mette insieme delle casistiche che ci saranno sul tema d'esame.
